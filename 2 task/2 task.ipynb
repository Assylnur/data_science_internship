{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "836ba7a4",
   "metadata": {},
   "source": [
    "### Data science Internship \n",
    "#### Task 2 : Building an algorithm for predicting the changes in inflation or dollar exchange rate\n",
    "#### Prepared by: Assylnur Lesken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7174c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# For scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "import  docx\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import pdfminer\n",
    "\n",
    "# Text\n",
    "import re\n",
    "import stanza\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# NN\n",
    "import math\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f173b",
   "metadata": {},
   "source": [
    "## 1. Collecting Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bce23",
   "metadata": {},
   "source": [
    "#### 1.1 Scraping\n",
    "\n",
    "The dataset for independent variable scraped from the website https://nationalbank.kz, using BeautifulSoup python library. A total of 268 files should be downloaded from various web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed9c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = dict()\n",
    "for i in range(1, 29):\n",
    "    html_text = requests.get('https://nationalbank.kz/ru/news/doklady-i-vystupleniya?page='+str(i)).text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "    links = soup.find_all('a', class_=\"posts-files__icon-wrap\")\n",
    "    time = soup.find_all('time')\n",
    "    title = soup.find_all('div', class_=\"posts-files__title\")\n",
    "    for link in links:\n",
    "        files[('https://nationalbank.kz' + link.get('href'))] = [link.get('title'), \n",
    "                                                                 title[links.index(link)].find('a').text.replace('  ', '').replace('\\n', ''),\n",
    "                                                                 time[links.index(link)].get('datetime')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb37a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    filename = './pdf2/'+ url.split('/')[-1]\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url)    \n",
    "    except urllib.error.URLError as e:\n",
    "        print(url, 'not downloaded')\n",
    "        return  \n",
    "    \n",
    "    filename +='.'+files[url][0]\n",
    "    file = open(filename, 'wb')\n",
    "    file_names.append(filename)\n",
    "    file.write(response.read())\n",
    "    file.close()\n",
    "    \n",
    "file_names = list()\n",
    "for i in files:\n",
    "    download_file(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f705ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(filename):\n",
    "    \n",
    "    if filename.split('.')[-1]=='pdf':\n",
    "        text = pdfminer.high_level.extract_text(filename)\n",
    "        return text.replace('\\n', '')\n",
    "    else:\n",
    "        doc = docx.Document(filename)\n",
    "        fullText = []\n",
    "        for para in doc.paragraphs:\n",
    "            fullText.append(para.text)\n",
    "        return '\\n'.join(fullText).replace('\\n', '')\n",
    "    \n",
    "texts = list()\n",
    "for i in file_names:\n",
    "    texts.append(getText(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33b3c737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Комментарии заместителя директора департамента...</td>\n",
       "      <td>Комментарии заместителя директора Департамент...</td>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Основные тезисы заместителя Председателя Нацио...</td>\n",
       "      <td>Основные тезисы заместителя Председателя Наци...</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Комментарий начальника управления мониторинга ...</td>\n",
       "      <td>Комментарий  начальника управления мониторинга...</td>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Доклад НБ РК на пленарном заседании Сената Пар...</td>\n",
       "      <td>Доклад НБ РК   на пленарном заседа...</td>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Доклад НБ РК на заседании Правительства РК «Об...</td>\n",
       "      <td>Доклад НБ РК на заседании Правительства РК «Об...</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Комментарии заместителя директора департамента...   \n",
       "1  Основные тезисы заместителя Председателя Нацио...   \n",
       "2  Комментарий начальника управления мониторинга ...   \n",
       "3  Доклад НБ РК на пленарном заседании Сената Пар...   \n",
       "4  Доклад НБ РК на заседании Правительства РК «Об...   \n",
       "\n",
       "                                                text       date  year  month  \n",
       "0   Комментарии заместителя директора Департамент... 2022-06-24  2022      6  \n",
       "1   Основные тезисы заместителя Председателя Наци... 2022-06-21  2022      6  \n",
       "2  Комментарий  начальника управления мониторинга... 2022-06-16  2022      6  \n",
       "3              Доклад НБ РК   на пленарном заседа... 2022-06-16  2022      6  \n",
       "4  Доклад НБ РК на заседании Правительства РК «Об... 2022-06-14  2022      6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['title'] = [i[1] for i in list(files.values())]\n",
    "df['text'] = texts\n",
    "df['date'] = pd.to_datetime([i[2] for i in list(files.values())])\n",
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "\n",
    "df.to_csv('data3.csv')\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d6524f",
   "metadata": {},
   "source": [
    "#### 1.2 Filtering text\n",
    "For tokenization and lemmatization text I use the library Stanza. For stop words I downloaded them from nltk.corpus, and added some own words to list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('ru')\n",
    "nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner,lemma')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c20e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "stpwrd = [\"«\", '»', '!', ':', '.',  '”', '“','...',  '-', '–', '?', '.', \"национальный\", \"банк\", \"это\", \n",
    "          \"который\", \"также\", \"наш\", \"мочь\", \"являться\", \"год\", \")\",\"(\",\n",
    "         'комментарий', 'доклад',' тезис' ,'г ', 'всё', 'стать', 'п', 'поэтому', 'данный', 'торг', 'образ',\n",
    "         'газета', 'департамент',' управление', 'заявление',\n",
    "          'иметь', 'несмотря','п', 'очень', 'вода', 'дуть', 'кликушествовать', 'оман', \n",
    "          'нб', 'рк', 'нбрк', 'тезис', 'из-за'\n",
    "         ]\n",
    "for i in stpwrd:\n",
    "    stop_words.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f59946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function returns filtered text\n",
    "def filter_tokens(tokens):\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and len(token)>2:\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "filtered_text =  []\n",
    "for txt in df.text:\n",
    "    \n",
    "#   Remove URLs from text\n",
    "    txt = re.sub(r'http\\S+', '', txt)\n",
    "    txt = re.sub(r'www\\S+', '', txt)\n",
    "    \n",
    "#   tokenization and lemmatization\n",
    "    doc = nlp(txt)\n",
    "    norm_form  = [word.lemma.lower() for sent in doc.sentences for word in sent.words]\n",
    "    y = [re.split('[^а-яА-Яa-zA-Z]',i.lower()) for i in  norm_form]\n",
    "    y = ([' '.join([j for j in i if j!='']) for i in y ])\n",
    "    \n",
    "#   Removing stopwords\n",
    "    filtered_text.append([i for i in filter_tokens(y ) if i!=''])\n",
    "    \n",
    "    \n",
    "df['filtered_text'] = [' '.join(i)for i in filtered_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07e373b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAykAAAE/CAYAAABCeozFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABSAElEQVR4nO3deZyVZf3/8ddbBEQREEETXDDADRWMQUXRcPmaleaGXzI3NCOttEy0+mlKWVZi2dcslUxxS03cqVxSAc2NAdncEpdyRxQhFDf8/P64ryM3hzMzZ3BmzmHm/Xw85sF9rvu6r/u67+MyH67lo4jAzMzMzMysWqxR6Q6YmZmZmZnlOUgxMzMzM7Oq4iDFzMzMzMyqioMUMzMzMzOrKg5SzMzMzMysqjhIMTMzMzOzquIgxczM2iRJYyVdXc/5EyS9LmmJpPVbsm9mZm2dgxQzM6sKkn4k6W9FZc/UUfbVZu5Le+A3wD4R0Tki3mzO+5mZ2YocpJiZWbWYCuwqqR2ApM8A7YHPFZX1S3XLJmnNRvZlQ2At4PEmas/MzBrBQYqZmVWLaWRByaD0eXfgPuDporJnI+IVSb0k3SbpLUnzJH2j0FCayjVR0tWSFgOjJG0uaYqk/0q6G+hRqhOStkj3BHhb0r2pPCR9W9IzwDOpbD9JMyW9LelBSdvn2tlB0ox0v+slXSfpZ+ncKEkPFN03JPVLxx0lnSfpP2nK2cWSOqVzwyW9JOkUSfMlvSrpmFw7nST9WtK/JS2S9EAq+6ukE4vuOVvSgeV8OWZmLclBipmZVYWI+AB4hCwQIf15P/BAUVlhFOVa4CWgFzACOEfSXrkmDwAmAt2Aa4A/A9PJgpOzgaPr6Me/gAHpY7eI2DN3+kBgJ2AbSZ8DLgO+CawPXALclgKMDsAtwFVAd+AG4JBy3wXwK2ALsuCsH9AbODN3/jNA11T+deD3ktZL584DBgO7pHufBnwMXAEcUWhA0sB0/QrT6czMqoGDFDMzqyZTWB6Q7EYWpNxfVDZF0ibAMOAHEfFeRMwELgWOzLX1UETcEhEfAz2BIcCPI+L9iJgK3L4K/ftFRLwVEUuBbwCXRMQjEbEsIq4A3gd2Tj/tgd9GxIcRMZFspKhBkpTaPjnd67/AOUB+Hc6HwE9T238DlgBbSloDOBb4bkS8nPr1YES8D9wK9JfUP7VxJHB9Cg7NzKqKgxQzM6smU4FhaVSgZ0Q8AzwI7JLKtk11egGFX+AL/k02MlDwYu64F7AwIt4pqt9Y+TY3A05JU73elvQ2sEm6Vy/g5YiIVbhfT2BtYHqu3TtSecGbEfFR7vO7QGeyUaK1gGeLG02Byl+AI1IwcxjZSI+ZWdVxkGJmZtXkIbJpTKOBfwJExGLglVT2SkQ8nz53l7Ru7tpNgZdzn/MBwqvAepLWKarfWPk2XwR+HhHdcj9rR8S16X6906hIqfu9QxaIAJ9sCFCwAFgKDMi12zUiOpfRvwXAe0DfOs5fARwO7AW8GxEPldGmmVmLc5BiZmZVI02jqgW+TzbNq+CBVDY11XuRbITlF5LWSgvWv0629qRUu/9O7f5EUgdJw4D9P2V3/wgcL2knZdaR9OUUOD0EfAScJGlNSQcDO+aunQUMkDRI0lrA2FxfP05tny9pAwBJvSV9oaEOpWsvA36TNhZoJ2mopI7p/ENk61N+jUdRzKyKOUgxM7NqMwXYgCwwKbg/leW3Hj4M6EM2qnIzcFZE3F1Pu18jW/T+FnAWcOWn6WRE1JKtHbkQWAjMA0alcx8AB6fPC4GRwE25a/8F/BT4B9lOYSvs9AX8ILX3cNqd7B/AlmV2bQwwh2wNzFtki/Dz/7+/EtgOqDORpZlZpWnF6bJmZmbWHCRNAF6KiDMq3I+jgNERMayS/TAzq49HUszMzNoISWsD3wLGV7ovZmb1cZBiZmbWBqQ1LW8Ar5PljDEzq1qe7mVmZmZmZlXFIylmZmZmZlZVHKSYmZmZmVlVWbPSHbDq06NHj+jTp0+lu2FmZmZmrdz06dMXRETP4nIHKbaSjdfpwt+//r1Kd8PMzMzMmlnPE46o6P0l/btUuad7VZikcZJmSnpN0svp+KeSTpU0TdJsST9JdftImpu7dkTadx9JEyQ9n66fKWmXlGl4XK6db1boMc3MzMzMyuaRlAqLiFMBJI0FlkTEeZL2AUYAOwICbpO0O/CfBpo7NSImFj5IGg0sioghkjoC/5R0V0Q83xzPYmZmZmbWFBykVKd90s9j6XNnoD9ZkNJX0sxU3hWY0kA720sakavfH1gpSEkBzWiAjbuv/ym7b2ZmZma26hykVCcBv4iIS1YolPoAz0bEoPR5BLBfA+2cGBF3NnTDiBhPykA8aLPPOnmOmZmZmVWM16RUpzuBYyV1BpDUW9IGq9jOCZLap3a2kLROE/bTzMzMzKzJeSSlCkXEXZK2Bh6SBLAEOAJY1simLgX6ADOUNfQGcGBDF63Zs3vFd3owMzMzs7ZLEZ7ZYyuqqamJ2traSnfDzMzMzFo5SdMjoqa43CMptpIP57/IK7//fqW7YWZmZmZl6PXt31S6C03Oa1LMzMzMzKyqOEipkJSY8SlJV6REixMlrS3pBUk9iupOkjQ8HS/JlddImpyOu0u6JbX1sKTtU/lYSWPS8Q8lXd5Cj2hmZmZmtkocpFTWlsD4iNgeWAx861O09RPgsdTW/wOuzJ+UdBSwG/CNUhdLGi2pVlLtm0uWfopumJmZmZl9Ol6TUlkvRsQ/0/HVwEnp+D5JHwNzWDmo6JRL5tgJeDUdDwMOAYiIeyWtL6lrOrc3sCewU0R8VKoj+TwpAzfd0LspmJmZmVnFeCSlsoqDgcLnPYBB6fORRXWWRsSglNDx8Fy56mn/s2RbGP8mbUVsZmZmZla1HKRU1qaShqbjw4AHCici2xv6LaBDmW1NJQUtaf3KgohYnM6Nj4i/AM9Tx3QvMzMzM7Nq4elelfUkcLSkS4BngIuAE4FJabrXEuBMYN8y2hoLXC5pNvAucHSJOqeQJYi8PSJeLXEegPYbbNIqt7IzMzMzs9WDkzlWiKQ+wKSI2LbSfSm29Wbd4rLTh1W6G2ZmZmbWgKGjJ1W6C59KXckcPd3LzMzMzMyqioOUComIFxoaRaknl8pekh6TNEfSZZI6pvpDJD0oaZakRyWtK+k+STMlLZH0dDr+Sss8pZmZmZlZ4zlIqX7FuVS+D0wARkbEdmTrik6Q1AG4HvhuRAwk23Z4aUTskXYCqwUOTzuD3VaB5zAzMzMzK4uDlOpXnEtlL+D5iPhXKrsC2J0smHk1IqYBRMTiunKilJJP5rhwyQdN2H0zMzMzs8ZxkFL9yt3ZQI2ou/JNIsZHRE1E1KzXudxdj83MzMzMmp6DlOpXnEvlH0AfSf1S2ZHAFOApoJekIQBpPYq3mDYzMzOz1Y5/ia1+xblUvgs8DNyQgpBpwMUR8YGkkcDvJHUClpKtS1nS2Buu07Pfar+dnZmZmZmtvhykVL+PI+L4orJ7gB2KK6b1KDuXaiQihjd918zMzMzMmp6DFFvJwgXPMPHycpLcm5mZmX16I465o9JdsCrjNSktQFIPSR+kHCXzJE1SZpykuSnfychc/eGSFgG3AD0kjcmdeyHVf0LS3FS2Y8qP8lj6c8tUPkrSrZLuSDlSzmrhRzczMzMzazQHKS2jHfBSyldyXCo7GBgEFHKajJO0Ua7+lFT/4hJtfR74Uq7sKWD3iNgBOBM4J3duR+DwdK9DJdU0yROZmZmZmTUTT/dqGZ2Bt4rKhgHXRsQy4HVJU4AhwG1AJ+C9OtoqnOuSK+sKXCGpP9k2xO1z5+6OiDcBJN2U7ltb3Kik0cBogB7rr9WohzMzMzMza0oeSWkZmwMvFZWpnvq9gFeKCyWtBawREe8WnTobuC8itgX2B/JRRnHulJK5VPJ5Uro4T4qZmZmZVZCDlJZxKFC8p+9UYKSkdpJ6kmWNf1RSO7KpYP9kZSOAh0qUdwVeTsejis79j6TuaVviA+to18zMzMysani6VzOT9C2yaVSfl/QdsqlfPYE/ArOBWWSjG6dFxGuS/kyWD+XGonYOAk5g5SAE4Fyy6V7fB+4tOvcAcBXQD/hzRKw01avYej36e5cNMzMzM6sYRZSc/WNNRNJYYHJETM6V7Qf0iIgJzXzvUUBNRHynMdfV1NREbW2DsYyZmZmZ2aciaXpErLSxk0dSmt9EYH5R2QygYwX6Upb5bz3DBdd8odLdMDMzs9XESYffWekuWCvjIKWZRcTcEmUrLYovh6SjgDFk08NmA8uASRExMeVS6RwRYyXtDRwfESNSPpUHyXYFWwocExFPr+rzmJmZmZk1NwcpqwlJA4DTgV0jYoGk7sBvyri0kEPloxS8nAMc0oxdNTMzMzP7VBykrD72BCZGxAKAiHhLqm8X40/Ul0PlE/k8Kes5T4qZmZmZVZC3IF59iDpynDSgvhwqn8jnSencxXlSzMzMzKxyHKSsPu4B/lfS+gBpulc56suhYmZmZmZWdbwF8WpE0tHAqWQL5h9LxTsBbwK9gXbAf8gCk6fTwvmhwBXAG2Q5VI6MiD713cdbEJuZmZlZS/AWxK1ARFxBFnA05pqHgC1yRT9u0k6ZmZmZmTUxBym2khfefoZjbt630t0wMzOzKnT5QXdUugvWBnhNipmZmZmZVRUHKVVIUh9Jc3OfR0iakI5PlTRN0mxJPymj/v6SHpH0mKR/SNqwZZ/GzMzMzKxxHKSsRiTtA/QHdgQGAYMl7d7AZQ8AO0fEDsB1wGl1tD1aUq2k2vcWf9CEvTYzMzMzaxyvSVm97JN+Cjt7dSYLWv4D9JU0M5V3Baak442B6yVtBHQAni/VcESMB8YD9OjX1Vu+mZmZmVnFeCRl9SLgFxExKP30i4g/pXPPFsrJtiku+B1wYURsB3yTOpI5mpmZmZlVCwcpq5c7gWMldQaQ1FvSBg1ck0/meHRzds7MzMzMrCl4ulf12lzSA+l4faA7cD3wZ+AhSQBLgCPIkjvWZSxwg6SXgYeBzRu6cZ9u/b29oJmZmZlVjDPOtwBJw4ExEbHfp2hjFEBETGiSTtWja7/eseu4E5r7NmZmZqu9vx10RqW7YLZac8b51d+MSnfAzMzMzKwleE1KmfK5SCS1l/ScpAslTZA0IldvrqQ+6fh3kuYA3wI2knSfpFmS+ufqT5D0vKSZkj6Q1COVXyzpyVS+LCJmA90lTcpdO0bS2HQ8StKF6XhLSR8V+iXpy5IeT229URiVMTMzMzOrRg5SVs1osvUgdZI0DNgOGEiWq2Qd4EvAj4Ff5qq2A05Ju3K9kq7dDtgFGJDKlzayf2cDT+U+/xQ4OrV1fSPbMjMzMzNrUQ5SGknS2sAxwEW54nFplGIm0DeVDQHujYiPgdnAvIhYCtwD7JS7thPwXtFtlpHlNOmwCv0bTPa91ha1t24D132SzPGDxe809rZmZmZmZk3GQUrjfY8s6WF+dOPUXI6SZ1OZ6rg+is71Io2gfFIh4gngL8D8FPh0akT/fkY2WpN3CnC5pKeAkSU7FTE+ImoioqZDl3UacTszMzMzs6blIKVxugIHApeVUbcW2FPSGsD2QD9JnYC9gWkAkvoBfYAnSly/CPi/Rk73+jzwakQ8WVT+MvAqUIOne5mZmZlZlfPuXo2zMdlWwh+lPCV1ioipkp4EZpEFIUuAvwE9gEMl9QJuBUZHxAf5ayXtAuxDtoal2C65/Cm9gXaSbk2f+wNfLmqrI3AFcFxELGmo3wD9u23kLRXNzMzMrGKcJ6UFNEWelHraHgtMjojJTdVm1759Yti5DlLMzKxy/nrIcZXugpm1AOdJab3uBf5d6U6YmZmZmTUVr0kpU8qTEpKOT5/bSXo55Tn5JFeKpONSvUK+kz7A34GNJf2nkMsknZss6em0M9iSVFZfvpMzJU1LuVjGS1JETAWukPRbSQ+mczvm7jFG0mvpHm/lc7qYmZmZmVUjBymNM49s4TzAvsCL+ZOS1gKOB+bnitsBz6QF8GcWtdcOOCydK6U438mFETEkIrYl2/ErP31snYjYhSxxZH5hfzvgD+ket9XzbGZmZmZmVcFBSuO8D8yTNAA4Eri66Py3yRap53fjKpUHpcFzdeQ72UPSIymL/Z7AgNy5ayFbsA90kdQtlXcG3qr/sYrzpPy3oepmZmZmZs3GQUrjXQ6cRrae57VceRfgMOCSovor5UEpOvdqHedWyHeSRmn+AIyIiO2APwJr5eoX74BQ+Lw58FId91heeYU8KfXmfTQzMzMza1YOUhopIqYDG5AFK3knAxcUbycMHAr8s7gdScOAhRGxsMRtSuU7KQQkCyR1BorXlozMtbsoIhal0ZRhZFnuzczMzMxWC97daxVExBcBihahi6LpX5LOBdYBfl9UPgS4ADi2jluslO8kIt6W9EdgDvACKSFkzkJJD5KN6BTavYssoLo/5UfZlCwAmljf8/Vfr4e3fjQzMzOzinGelFZA0mSyPCy1xeURMbyobGJE1LvDV01NTdTW1tZXxczMzMzsU3OelLbppyXKzm/oonkL32b/iTc1Q3fMzKySbh9xcKW7YGZWFq9JqYOkIyRNTz8XSuqQ8prUpBwpt0k6JtUdJOlhSbMl3SxpvVQ+WVJNrs1CLhRJGpdymsyRVFhPMjzlWNk3fV5P0tKUVX6F9iT9rNAeMDb9IOnzaQewrsCjku6RNCPd54CIWGl9jJmZmZlZNXGQUrcbImJwRAwm24Hre7lzlwAPR0Rh8fyVwA8iYnuyNSNnNdD2wcAgYCCwNzBO0kbp3AzgqHT8NWBW8cWSNgD2KlG+HfB/wEERsYhse+ODIuJzwB7Ar5UWp5iZmZmZVStP96pDRLwv6R9AD7KdtV5Op8YCOwKbAKQRi24RMSWdvwK4IdfUNZIKeVM6pT+HAddGxDLgdUlTgCHAYrKAqKOk7sBXyBIwdijq3o+Bc0i5UZJeZJntfx0RhS2PBZwjaXfgY6A3sCErbp1Meo7RwGiATj161PtuzMzMzMyak0dS6hERe6dM7cezPO/I+2QjKaeX2czhETEotVMIVhoazfgz8EvgaaB4S+M+wLYRcXtR+VZk2ea/Kaln4d5AT2Bwuv/rrJhb5RMr5knp2uBDmZmZmZk1FwcpdZD0mbR2pB1ZJvl/pFO/AM4GviJpQJpWtVDSbun8kcCUlVtcwVRgZFrb0hPYHXg0d/524HPAZSWuPYvS08nujYjbyEZY/i+VdQXmR8SHkvYANmugX2ZmZmZmFefpXnXbC/gR0A64n2xXrH0BIuIDSd8Gxqfg5GjgYklrA88BxzTQ9s3AULL1JgGcFhGvSdqq0D5QWCC/d9G1L0XE1LoajogrJR0u6UvANcDtkmqBmcBT5Tx4v/W6eQcYMzMzM6sY50mxlThPipmZmZm1BOdJsbI9u3AJB934QKW7YWZW9W4+ZFilu2Bm1ip5TUoTk3S2pO/mPv9c0kmSpqYcKk9IuljSGun8YSmHyVxJv8pdt0zSTEnzJF1b2Do45W95NJ27JK2Z+SQHSzquSVnokTRW0pgWenwzMzMzs0/NQUrT+xPZGhVSIPJVsu2LdwROAbYD+gIHS+oF/ArYkyxvyhBJB6Z2lqYdubYjy3HSTdLWwEhg13RuGdkOXmZmZmZmrYanezWxiHhB0puSdiDLSfIY8CbwaEQ8ByDpWrJcKR8CkyPijVR+DdlOX7cAnSTNBDYGbomIhZIOBwYD09LASidgfrp1oX6h/NVct06WdATwDnBKRDxc3O8V86Rs2ARvwszMzMxs1ThIaR6XAqOAz7B8G+HiHQqC+vOlLI2IQZLWBO6WtEuqf0VE/Kiu+pBN9wLOy507PyLOSzuF/QbYpfjiiBgPjAdYr+9W3k3BzMzMzCrG072ax81k2xUPAe5MZTtK2jxNARsJPAA8AnxeUo+0tuQwinKsRMRHwLtkme/vAUZI2gBAUndJjcl98iYrZ683MzMzM6sqHklpBimPyn3A2xGxLE3Neogsi/x2ZMkcb46IjyX9CLiPbJTkbxFxa2qmMH2rPfA4cEdq9wzgrhTsfEiWaPLfDXTp22mty9pkuV/MzMzMzKqW86Q0gxRAzAAOjYhnJA0HxkTEfhXtWJmcJ8XMzMzMWoLzpLQQSdsAk8hGSp6pdH9WxYtvf8BJN79Y6W6YmVWlCw7apNJdMDNr9RykNLGIeAL4bFHZZGByJfpjZmZmZra68cL5FiTpKEmzJc2SdFVKyDgzl7hxpqRekiZL+q2kB1OSxx3T9TumssfSn1um8lGSLszd50JJo9LxmZKmpXbGF5JCmpmZmZlVK4+ktBBJA4DTyRIxLpDUPSLeSueWFLYPTp8B1omIXSTtTraN8bbAU8DuEfFR2k74HOCQBm59YUT8NLV7FbAfcHuJ/n2SJ2Xdnr0/1bOamZmZmX0aDlJazp7AxIhYAFAIUOpxbao3VVIXSd2AdYErJPUny7PSPld/pKRh6bg3UFj5voek08h29upOtlPYSkFKPk/Khv22924KZmZmZlYxnu7VcsTKCR3rUyr549nAfRGxLbA/sFbu/PURMSiNyFwPIGkt4A/AiIjYDvhj0TVmZmZmZlXHQUrLuQf4X0nrQ5aIsYH6I1O9YcCiiFgEdAVeTudHlXHPQkCyQFJnYERjO21mZmZm1tI83auFRMTjkn4OTJG0DHiM+gONhZIeBLoAx6ayc8mme30fuLeMe74t6Y/AHOAFYFo5fd2kWwdvsWlmZmZmFeNkjlVI0mSy5I8VyajYr++gOPdX/6jErc3M6nTwiB6V7oKZmTWxupI5erqXmZmZmZlVFQcpZZDUR9LcdLx1ynOyiaRbJE2X9HjawrdQ/6GUy+RxSYeksv0lPZLK/yFpw1R+gaQz0/EXJE0l2wnsRUk3p3vNkrSLpHEpl8prkl5Oxz+V1FnSPZJmSJoj6YDifqfPIyRNaLEXZ2ZmZma2CrwmpREk9QauA74WES9KOjYi3pLUCZgm6caIeDMihqb6+wA/AW4EHgB2joiQdBxwGnAK8MN07f3ABcCXIuJjSRcAUyLiIEntgM4R8WBqdyywJCLOS5/XBA6KiMWSegAPS7qtxV6MmZmZmVkTcpBSvs7AHcC9EfF4KjtJ0kHpeBOgP/CmpA2A+4BNgcPS+Y2B6yVtBHQAngeIiHclfQOYCpwcEc+m+nsCR6U6y4BF9fRNwDkp8ePHZHlSNkzn+kqamY67AlNKNpBL5tijx8b1vwkzMzMzs2bk6V7l2wT4BVlyxK0lDQf2BoZGxECy3brWAoiI+RExANgHOCFd/zuy7O/bAd9kxXwl2wFvAr1WsW+HAz2BwSlPyuu59p/N5U85ta4GImJ8RNRERE3XLuuvYjfMzMzMzD49BynlezIi/gycCFxCNiqxMI2EbAXsDFkCRUkd0zXvAdum43yOk6MLjUrajGza1w7AFyXtlE7dQwpwJLWT1KWevnUF5kfEh5L2ADb7dI9qZmZmZlY5nu7VSBExRdJTQB9gTUmzgaeBh1OVDYFbJYns/X4vlY8FbpD0cqq7earzJ7Lthl+R9HVggqQhwHeB8alsGVnA8lAd3boGuF1SLTATeOrTPGO39db0Vp9mZmZmVjFtPk9KmrY1JiL2q3BXmo2kX5GtcXkdOCQi3q+vfk1NTdTWViRFi5mZmZm1IXXlSfFIShsQET9oTP13F3zEY5fOb67umJmVtMNxG1S6C2ZmViXa7JoUSb+TNAf4FrCRpPtSPpL+kiZIGpHqHScpJPWoL+9IPXlQxkoak7tmUhq9QdK+KbfJLEn3pLLuKf/KbEkPS9o+187LqfwpSXum8k/6mrvHmLRNMZImS6pJxz+TtKQ53qeZmZmZWVNpk0GKpGFkO2oNJMtfsg7wJeDHwC9z9dYCjgfKGVYo5EHZgSyXymkN9KEn8Eey6VcDgUPTqZ8Aj0XE9sD/A67MXXZ+Kv8T0KjpaWlb5L0ac42ZmZmZWSW0ySAFGEKW7+RjYDYwLyKWku2otVOu3reBK4ClubK+KdP7TGBcrnxj4M40OnMqMCB37uTcNbulsp2BqRFRyJfyViofBlyVyu4F1pfUNdfOE8APgMtz7Rcy0d8jaYs6nvnHwDl1vRBJoyXVSqpd+N8366pmZmZmZtbs2mqQojrKI3euC1kixkuK6tSVd6S+PCjn5665P9eHUrsWlOpbod75EbEN8FXg17nzp6a2ryXbRaxYH2DbiLi9xLnsBrk8Keut6zwpZmZmZlY5bTVIqQX2lLQGsD3QT1InsuSM01Kdk4ELIuKDMtssmQelHg8Bn5e0OWRrUVL5VLLkjIWdxxZExOKiaxcDpfYIfpMsm32xs9KPmZmZmVnVa5O7e0XEVElPArOAJ4AlwN/IfvE/FPgh2YjG1Y1odixFeVAa6MMbkkYDN6VgaT7wP6mdy1P+lXdZMeA5WdIRZN/bmFz52ZK+B3QkG8XZs+h2L0XE1HIfZO0ea3qXHTMzMzOrGOdJaQN5UhrLeVLMzMzMrCU4T4qV7cPX3+e18+ZVuhtmVoU+M6ZfpbtgZmZtQFtdk/KJiJjcnKMoKbfK0rT71nOSzpPUOe3ENUPSHEkH1FH/P5IuTOUTUl6WtSVdK+nJlF9l/3T+mnTNW5KeT8fHp/buT/eaIWmX5npWMzMzM7Om4JGUlvFsRAxKCR4fJ1vzclBELJbUA3hY0m2Rzb1rBzyT6o8Cioe/TiVbHL8N2bbHD0l6ICIKi+0nAJMiYmL6vDbwPxHxnqT+ZDuArTSkZmZmZmZWLRyktIy+KUfK5sB5ZIvyz5G0O/Ax0BvYEHgN6AS8V0c744D1gKNTQPOipGnADsC9dVzTHrhQ0iBgGVAyj0paxD8aoHe3Xo18PDMzMzOzpuMgpWUURlLWJtv+GKAnMDgiPpT0AsvzqvQCXqmjnVOB/Vk5v0p9ux+cDLwODCSb3lcyAIqI8cB4gIGbbNe2d1MwMzMzs4pq82tSWtj7ZKMZi4H5KUDZA9gsV+dQ4J/1tHEfcKQyvYHBwGP11O8KvBoRHwNHkk0nMzMzMzOrWh5JaRmF6V4dgbuBa4DbJdUCM4GnACSdC6wD/L6etq4GhgBzgI+AEyLi7Xrq/wG4UdKhZAHOOw11tv2GHb2Dj5mZmZlVTJvPk2Irc54UMzMzM2sJzpNiZftw/n95/YLJle6GmVWZDU8aXukumJlZG+E1KWZmZmZmVlUcpDSCpKMkzU5JFK8qJFjMnZ+bkif2kTQ3lbVPSRwLSRl/JumX6XispDHp+EJJp6TjnpJulDQt/exaXD99niRpeDpekiu/X9KkdLyOpMtSO4/lE0eamZmZmVUjByllkjQAOB3YMyIGAt8t89LRwJLc5x8DfSQdm2v7u0DHiPh1Kvo/4PyIGAIcAlzaiH5+mWxHr4LTgXtTW3sA4yStU+K60ZJqJdW+tWRRubczMzMzM2tyXpNSvj2BiRGxACAi3pIE2S/9Z6Q6ffMXpLwoxwAXAQPSdSFpLDALeIAsmePni67dG9gmtQ/QRdK66fhkSUek40JyyML9RBaUnAMU6uwDfCU3ArMWsCnwZL6vK+RJ2XRL76ZgZmZmZhXjIKV8onTSxFMjYiJk072Kzn2P7Bf/D4rKfwUcC/ycLLni8cAvgcPT+TWAoRGxdIUOZEHL+RFxXvo8qajdw4DJZJnr8/0+JCKervfpzMzMzMyqhKd7le8e4H8lrQ8gqXsD9bsCBwKX5Qsl7Q+8FxHXABOASyPiMqBbSuwIcBfwndw1g8ro3xpk2eXPLSq/EzgxjbIgaYcy2jIzMzMzqxiPpJQpIh6X9HNgiqRl1J/lHWBjYExEfFSYtiWpE9noyb4l6p8ITJS0M3AS8HtJs8m+o6lkoy316UQ2He3t3DQxgLOB3wKzU6DyArBffQ2132BdbzVqZmZmZhXjZI62Ekn/BTw9rDw9gAWV7sRqxO+rfH5X5fO7ahy/r/L5XZXP76px/L6W2ywiehYXeiTFSnm6VOZPW5mkWr+r8vl9lc/vqnx+V43j91U+v6vy+V01jt9Xw7wmxczMzMzMqoqDFDMzMzMzqyoOUqyU8ZXuwGrE76px/L7K53dVPr+rxvH7Kp/fVfn8rhrH76sBXjhvZmZmZmZVxSMpZmZmZmZWVRyk2Cck7SvpaUnzJP2w0v2pNEmbSLpP0pOSHpf03VTeXdLdkp5Jf66Xu+ZH6f09LekLlet9ZUhqJ+kxSZPSZ7+rOkjqJmmipKfSP2ND/b5Kk3Ry+ndwrqRrJa3ld7WcpMskzZc0N1fW6PcjabCkOencBYUkwK1JHe9qXPr3cLakmyV1y51rs+8KSr+v3LkxkkJSj1xZm31fdb0rSSem9/G4pHNz5W32XZUtIvzjH4B2wLPAZ4EOwCxgm0r3q8LvZCPgc+l4XeBfwDbAucAPU/kPgV+l423Se+sIbJ7eZ7tKP0cLv7PvA38GJqXPfld1v6srgOPScQegm99XyffUG3ge6JQ+/wUY5Xe1wjvaHfgcMDdX1uj3AzwKDAUE/B34YqWfrYXe1T7Amun4V35X9b+vVL4JcCfwb6CH31ed/2ztAfwD6Jg+b+B3Vf6PR1KsYEdgXkQ8FxEfANcBB1S4TxUVEa9GxIx0/F/gSbJfmA4g+wWT9OeB6fgA4LqIeD8ingfmkb3XNkHSxsCXgUtzxX5XJUjqQvY/tD8BRMQHEfE2fl91WRPoJGlNYG3gFfyuPhERU4G3ioob9X4kbQR0iYiHIvtN6crcNa1GqXcVEXdFxEfp48PAxum4Tb8rqPOfLYDzgdOA/MLmNv2+6nhXJwC/jIj3U535qbxNv6tyOUixgt7Ai7nPL6UyAyT1AXYAHgE2jIhXIQtkgA1Stbb+Dn9L9j+tj3NlflelfRZ4A7g8TY+7VNI6+H2tJCJeBs4D/gO8CiyKiLvwu2pIY99P73RcXN7WHEv2t9fgd1WSpK8AL0fErKJTfl8r2wLYTdIjkqZIGpLK/a7K4CDFCkrNefTWb4CkzsCNwPciYnF9VUuUtYl3KGk/YH5ETC/3khJlbeJdJWuSTQu4KCJ2AN4hm5JTlzb7vtJaigPIpkT0AtaRdER9l5QoaxPvqkx1vZ82/94knQ58BFxTKCpRrU2/K0lrA6cDZ5Y6XaKsTb8vsv/WrwfsDJwK/CWtMfG7KoODFCt4iWyOacHGZFMq2jRJ7ckClGsi4qZU/HoakiX9WRi+bcvvcFfgK5JeIJsquKekq/G7qstLwEsR8Uj6PJEsaPH7WtnewPMR8UZEfAjcBOyC31VDGvt+XmL5NKd8eZsg6WhgP+DwNM0G/K5K6Uv2Fwaz0n/vNwZmSPoMfl+lvATcFJlHyWYa9MDvqiwOUqxgGtBf0uaSOgBfBW6rcJ8qKv1tx5+AJyPiN7lTtwFHp+OjgVtz5V+V1FHS5kB/sgVwrV5E/CgiNo6IPmT/7NwbEUfgd1VSRLwGvChpy1S0F/AEfl+l/AfYWdLa6d/JvcjWh/ld1a9R7ydNCfuvpJ3Tez4qd02rJmlf4AfAVyLi3dwpv6siETEnIjaIiD7pv/cvkW0w8xp+X6XcAuwJIGkLsk1SFuB3VZ5Kr9z3T/X8AF8i28HqWeD0Sven0j/AMLJh1tnAzPTzJWB94B7gmfRn99w1p6f39zRtdEcOYDjLd/fyu6r7PQ0CatM/X7eQTQnw+yr9rn4CPAXMBa4i2xHH72r5815Ltl7nQ7JfGr++Ku8HqEnv+FngQlLC59b0U8e7mke2PqDw3/mL/a7qfl9F518g7e7V1t9XHf9sdQCuTs8+A9jT76r8H2ecNzMzMzOzquLpXmZmZmZmVlUcpJiZmZmZWVVxkGJmZmZmZlXFQYqZmZmZmVUVBylmZmZmZlZVHKSYmZmZmVlVcZBiZmZmZmZVxUGKmZmZmZlVlTUr3QGrPj169Ig+ffpUuhtmZmZm1spNnz59QUT0LC53kNLKSRoAXAx0BM6PiGsbumbjdbrw969/r7m7ZmZmZmYV1vOEIyp6f0n/LlXuIKWVi4jHgd0q3Q8zMzMzs3K1uTUpknpKmibpMUmzJO0m6RupbJakGyWtnas/QdLzkmZK+kBSD2XGSZoraY6kkanuoNRON0l9JM1N5cMk3S+pU/p8aqo3W9JPUtkn9dPnEZIm5PowIndubqq/wjW580vSn8MlTUrH3SUtkjSmGV6rmZmZmVmTaXNBSkS8ERFDImIH4PfAt4CbUtlA4Eng67lL2gGnRMQg4JVUdjAwCBgI7A2Mk7RRRMwEfgJcD7QHkPRZ4ALg0IhYKmkfoD+wY2pjsKTdm++JP/EjoORwWurnaEm1kmrfXLK4BbpjZmZmZlZamwtS4JMRj38BZwPnA9umkY45wOHAgFz1TsB7RU0MA66NiGUR8TowBRgCEBGTgC7A74DOwF+BGyPitXTtPunnMWAGsBVZ0ALQN43YzATGFd1zXO5c31z5J9dIOr2O5+0N7AzcXNc7iYjxEVETETXrd+5SVzUzMzMzs2bXJtekpBGPLSQdBhwNfAk4MCJmSRoFDM9V78XyEZQC1dW2pIOB54BFwP8ARwD/T9IfI2J+uvYXEXFJ0XV9gGfTiA1petd+uSqnRsTEdC4/xevZiBiUpqjNlDSxRLfOIgvIdqmr32ZmZmZm1aLNjaRIWldSu/TxPWBbYF3gVUntyUZSCnX7AX2AJ4qamQqMlNROUk9gd+BRSeuQTfc6BTgXeDLtpnU2y0dG7gSOldQ53aO3pA2a4NGWAu+Sppnl9AX6RMRdTXAPMzMzM7Nm1xZHUgYA4yUFEMB3gO2AR8jWbMwB1pXUC7gVGB0RHxS1cTMwFJiV2jgtIl6TdC4wPh33KVSOiL9IOlbS7hFxl6StgYckASwhG21ZtorPs7mkB8impU2NiLmp3YKtgGMa0+CaPbtXfDs6MzMzM2u7FBGV7oM1szSt7XvAh2RBV/HI0AoGbrph/P0Hh9dXxczMzMxagV7f/k1F7y9pekTUFJe3xZGUNidNOWswiaOZmZmZWTVoc2tSSkn5RpamHbKek3RePsdIqjNG0lhJfSXNyJX3lzRd0sh0/byUj2SmpL+lOksk/VrSDEn3pHUspLbuSNffL2mrVF5WXpSiXCo9leV4mZZ+dk3lYwu5USTtJSkkrRStmpmZmZlVCwcpyxV21hoKjKqrUkQ8CyySNCgVHQNMiIjr0/XHAfdHxKCI+FKqsw4wIyI+R7Zd8VmpfDxwYkQMBsYAf/gU/f8/4PyIGAIcAlxaos5ZwLxPcQ8zMzMzs2bn6V7L9U05SDYHzktlu6UygJ7AH9PxpcAxkr4PjCRLzFifj8kSPAJcDdyUdvfaBbght9C9Y+6acZLOKPStRD8BupIFPZAlldwm11YXSesWPkg6BJgGDC7VQUmjgdEAvddbt1QVMzMzM7MW4SBluXy+kVrgBbIRkf0gm+5FlpwR4EayUYl7gekR8WYj7xVko1hvF/KilFBvXpRUns+lsgYwNCKW5htJQUs74DTgy0CpPCpExHiykR0Gbrqhd1MwMzMzs4rxdK+VvU+2HfB6dVWIiPfI8p1cBFxeRptrAIU1Jl8DHoiIxcDzkg4FUGbgp+j3XWTbKZPaG5Q7dwTw14hY8CnaNzMzMzNrER5JWa4wjaojcDcwG9innvrXAAeTBQcNeQcYIGk6WSb6kan8cOCiNK2rPXAdWe6VVXES8HtJs8m+16nA8enchsD55TbUfoNNKr4dnZmZmZm1Xc6TsorS9K+uEfHjMuouiYjODdWrFjU1NVFbW1vpbpiZmZlZK+c8KU1I0s1ki9n3rHRfmsM7b8zjofH7NVzRzMzMzFZrQ0dParhSBVTdmpSinCUzJV0pabCkKSmfyJ2SNkp1B0l6WNJsSTdLWi+VT5b0dK6NZalcksalvCNzJI3M3Xd4Lr/Ja7ncIi9I6pGOr5Y0NyIOAt4E/pFyoBTu9ZVSeUmA4SVynEwu5CuRtI+kh1IelRvSzl9IGiLpQUmzJD0qaV1JoyRdmM5/Nb2P9qn9+1MbMyTtkrvXxZKezL8LMzMzM7NqVa0jKfkdrNqTbbN7QES8kQKLnwPHAleS5RmZIumnZDtufS+1cXhE1KY2lqSyg4FBwECgBzBN0tSIeJVsB6wpEfEVSWOLOyRpO2DbwueI2COVTwbG5O71udxl+bwkHwOiSAqAzgD2joh3JP0A+L6kX5JtWzwyIqZJ6gIszV23F/BdYJ+I+FDSfOB/IuI9Sf3JMszXpH7vAgyIiI9z78LMzMzMrCpVa5CStyVZcHB3bjvdVyV1BbpFRCFPyBXADQ20NQy4NiKWAa9LmgIMAW4DOgHv1XPtz8iCjp+X0+kSeUneAD4jqXtEvJWrujOwDfDP9HwdgIfInvvViJgGkHYDK2wpvB1wFHB0RPw3tdMeuDDt6rUM2CKVL0ttdqjv+fJ5Ujbs3qmcRzQzMzMzaxarQ5Ai4PGIGLpCYRakrEpbdekFvFLHuV2AJZS/89ZKeUkiYqmkM4H7JX0I9Mv16e6IOGyFjkrbk+VTKWVrsq2Mz5H097Ql8snA62SjRGuQApKIeELSX4D5kp4jC8ZWks+TsvVm3bybgpmZmZlVTNWtSSnhaaCnpKGQTf+SNCAiFgELJe2W6h3J8uzrdZkKjJTUTlJPYHfgUUntyKaC/bOO68YCZzaizyXzkkTE7yNiQJrKVtg+62FgV0n90vOtLWkL4Cmgl6QhqXxdSYWg8i8RMYksACr0qyvZyMvHZO+iXe7Wi4D/S/ddIdmjmZmZmVm1qfqRlIj4QFlm9QvS6MmawG+Bx4GjgYuVZYl/DjimgeZuBoaSjYgEcFpEvCbpz8AzZJnkS3kkIp6V1KfMbpedlyStsxkFXCupYyo+IyL+ldbf/E5SJ7LgYu+iy39BFmRdB/wBuFFZcsj7yHKzkBbQ7wN8qcy+s07PflW704OZmZmZtX7Ok2IrcZ4UMzMzM2sJcp4UK9fCBc8w8fJ9K90NMzMzM2tmI465o9JdKGl1WJPSaki6RVmul8fTblpIWpbyl8yTdK3S9l2l6qbyJZJ+nXKh3JPW1hTnXflZfqth50kxMzMzs9WJg5SWdWxEDAZqgJMkrQ8sTQvatwP2ALrVUxdgHWBGRHyObKOAs/I3kLQBsFfucz5PyiC8cN7MzMzMqpyDlJZ1kqRZZDt6bQL0BzpJmgm8CEyKiIX11IUsKeT16fhqstwveT8Gzsl9zudJqZOk0ZJqJdUuXvLBqjybmZmZmVmT8JqUFiJpONnuXEMj4t2UqX4t0khK2l747rQbV4c66paS3/mgD7BtRJyYZo2tUp6Uvn26ejcFMzMzM6sYj6S0nK7AwhR0bEWWaf4TEfER8C7Qo4G6awAj0vHXgAdy586iaPpX4jwpZmZmZrba8EhKy7kDOF7SbLIElQ+n8sJ0r/ZkuV/uIMtCX6ouZPlPBkiaThZ8jMydeykipuZvuip5Utbr0b9qd3owMzMzs9bPeVJWM5KWRETn5ryH86SYmZmZWUtwnpR6SJpAtmh9YqX7Ug3mv/UMF1zzhUp3w8zMzMya2UmH31npLpTkNSmrmeYeRTEzMzMzq7RWE6RI6iNpbu7zCEkTJPWUdKOkaeln13R+k/T5AaAfcISkWekaSTo5JT/8j6Q30vGl6dojJD2ayi6R1C6VFxIzzpT0dNqVC0ljJV0l6V5Jz0j6RiqXpHGS5kqaI2lkKh8uaVFq5zlJ30/la0m6PNV9TNIeRc/7VrrmNUljUnn3lBhytqSHJW3fAl+HmZmZmdkqazVBSj3+Dzg/IoYAhwCXpvKzgIuA4WSL1mdHxECgC7BfRJyfdsM6E7g+IgZFxHGStiZbrL5rOr8MODy1uTTVG5QrK9ge+DIwFDhTUi/gYGAQMJBsy+FxkjZK9e9P7YwEjkhl3waIiO2Aw4ArJBW2Jm4H3JKuuTh3358Aj0XE9sD/A64s9ZLyeVKWLHaeFDMzMzOrnNa2JqVv2ikLsm18p5D98r9NIW8I0EXSusAQ4KcR8ZGkJ4HZ6fw9wE7A7XXcYy9gMDAttdkJmF9G326NiKXAUkn3ATuSJWK8NiKWAa9LmpL6tRjYLT1LP+A7qY1hwO8AIuIpSf8Gtkh97wy8VeK+w8iCMyLiXknrS+oaEYvylfJ5Ujb9rPOkmJmZmVnltLYg5dk0koCkEcB+ZKNFQ1OA8AnlopYSGjp3RUT8qJF9K/7FPxq4z/0RsZ+kHsB0Sdc1UH9z4KUS5aWucRBiZmZmZlWrLUz3uovlIxFIGpQOa4G9U6b3rcmmYwHsCUyrp717gBGSNkjtdZe0WRn9OCCtKVmfbIrZNGAqMFJSO0k9gd2BR4uue5dstKZjqn94uu8WwKbA05I6APsDfy1x3/w1w4EFEbG4jP6amZmZmVVEaxtJKeUk4PcpMeKaZL+0Hw/8FLgROBb4ANhO0ixgDnBbXY1FxBOSzgDukrQG8CHZWpF/N9CPR8mCiE2BsyPiFUk3k61RmUU2unFaRLyWsswXpnutBfwmIhZJ+gNwsaQ5wEfAqIh4X9JfgAHADWmA6DPAMkl/BsYCl6fnfxc4uqEXtkH3/lW7HZ2ZmZmZtX5O5kjz50mRNBZYEhHnNVP7kyNieFHZecCFEfFCY9vr0a9r7D9uaBP1zszMzMyq1eUH3VHR+9eVzLEtTPdqC35aouxq4I2W7oiZmZmZ2afVFqZ7NSgiRjVz+2Obsj1JfchGfrZNWyKfL2kGsANpqhdZgHKbpHuBMWkR/ueBc4F9inf3MjMzMzOrFg5SVmOSegPXAV+LiMdT2VhyU8vSYnkkbUeWM+ZLDlDMzMzMrJp5utfqqzNwBzC5EKDUoxfwd7Ktk18pVSGfzPE9J3M0MzMzswpykLL62gT4BbBHmvJVn62AbwHfTFsdryQixkdETUTUrNWlQxN31czMzMysfJ7utfp6MiL+LOll4BJJn4+6t2q7NyJuk9SNbMrX11qsl2ZmZmZmjeQgZTUXEVMkPQWcAPyhgbpXSjpc0pci4m911evTrX/Ft6MzMzMzs7bLeVJsJV379Y5dx51Q6W6YmZmZWTP720FnVPT+zpNiZmZmZmarhQaDFEl9JC2VNFPSc5LOkzRc0qRcnTFp61sk9ZV0h6Tpku6XtFUqv1XSUen4m5KuSceTJdXk2lqSOz5V0jRJsyX9JNefkHR8+txO0sspazySJkgakY4vyvVrM0n3pLbukbRpcf30eW7KQ4Kk76fPcyV9bxXuf1yq26PEO3tBUo90fISkR9M7vkRSu1S+r6QZkmZJuieVjZU0Jh3/UNLl6XhHSQ9Keiz9uWUq7yDp5vQMcyS90NB3bmZmZmZWSeWOpDwbEYOAocCoBuqOB06MiMHAGJavkxgNnClpN+AU4MT6GpG0D9Af2BEYBAyWtHs6PQ84MB3vC7xY4vozgXa5RIoXAldGxPbANcAFDdx/MHAMsBOwM/ANSTs04v5rAccD81PRx4BK1NsaGAnsmt7xMuDwtAvXH4FDImIgcGjRdUcBuwHfSEVPAbtHxA7AmcA5qfwLQPuI2BbYo75nNjMzMzOrBuUunO8raSawOXBeKtstlQH0BP4oqTOwC3CD9Mnv4x0BIuL1FDjcBxwUEW/l2r9G0tJ03Cn9uU/6eSx97kwWtPwHeB+YJ2kAcCRwNZCfyzYK+B+ybXoLhgIHp+OryDKvF4yTVJiQ1zf9OQy4OSLeAZB0E1lQcFsZ9wf4NnAFWUAG8BKwtaS1IuK9XL29gMHAtPTOOpEFNjsDUyPieYCi97U3sCewU0R8lMq6AldI6g8E0D6VLwPWLozO1EXSaLJAkrV6dq2vqpmZmZlZsyo3SHk2IgZJWhuoBV4A7o+I/SCb7kUWRKwBvJ1GBErZDniTLLlg3uERUZvaKkz3EvCLiLgkX7EwFQu4HDgtPcNrRe11B04mC6iOqqMv+R0DTo2Iian9ubn716e++3cBDiML2E4BiIjnJP0ZmCHpA5a/A5ElWfxRvgFJXynqY95ngSOA30jaM209fDZwX0QclN7R5FT3LrLg7A3g5boeJiLGk42C0bVfb++mYGZmZmYV09iF8++T/c38eqVORsRi4HlJhwIoMzAd7wh8EdgBGCNp8wbudSdwbBqdQVJvSRvk7jUd2IAsWCj2m4j4A9ArTRsDeBD4ajo+HHiggftPBQ6UtLakdYCDgPvLvP/JwAURsULq9og4IyK2SUFcIfP7PcCIwrNJ6i5pM+Ah4POF9ySpe66p8RHxF+B5lk/36sryIGRU7p4fAUuBU/F0LzMzMzNbDTR2uldH4G5gNtlUrFIOBy5K06faA9cpy+PxR+CYiHhF0inAZZL2rOuGEXFXWq/xUJoGtYRs9GBZrs4XAfIL34t8E7hN0hDgpHTPU8lGFY6p74EjYkZaDP9oKro0Ih7LjeTUd3+RTQFrUEQ8kd7VXZLWAD4Evh0RD6cpWDel8vlkU9jyTiF7P7eTTV+7QtL3gXs/6Yj0v0CXiPhTYaF+Q/p326ji29GZmZmZWdvlPCm2kpqamqitra10N8zMzMyslVMdeVKccd5W8szCBXz5xksr3Q0zMzMza2Z/PeS4SnehJCdz5JPcJ3PT8dYpL8km9eRJmZu7dkSpHCnpczk5VxpsSynfi7IcNDPTz7Lc8a6SZuTa6S9pejp+QdKvlOVheVRSv2Z5iWZmZmZmTcQjKTmSegPXAV8jWxRfyJMi4BFJU4CFq9BuPudKo9oqke9lUCpfkt9FTdIiSYMiYma614RcM4sjYseUW+W3wH6NfQYzMzMzs5bikZTlOgN3AJMj4nFyeVIiYglQyJMCaSOBtJnAuKJ2xuXOrZRzpZFtjQJOB8pZxX4pcEzKhzIS+HPu3LW5P4eWuljSaEm1kmo/WPzfMm5nZmZmZtY8HKQstwnwC2CPtKtYfXlSno2IQWkk49Sic6fmzj2byla1rXy+l4bcSLbF837A9Ih4M3cu6jheXhgxPiJqIqKmQ5d1y7idmZmZmVnzcJCy3JMR8WfgROASspwodeZJaaR6c67Uo1S+l5JSFvs7gYtYOXfLyNyfDzWq52ZmZmZmLcxrUopExJSU12UnsnUddeZJaUSbDeZcacAn+V4i4t166l1Dll3+rqLyjpIeIQtKD2voZv3X61G1Oz2YmZmZWevnPCmtiKQxQNeI+HGu7AWgJiIWlNuO86SYmZmZWUtwnpRWTtLNZAv19/y0bc1b+Db7T7zp03fKzMzMzKra7SMOrnQXSmoVa1JSvpGlubwhz6c8IxMkXSzpfkn/krRfqt9O0jhJ0yTNlvTNXFs1kpakdv4j6cJUPkrSG7l7vCFpVDq3l6THJM2RdJmkjql8iKQHU96VRyWtm9q5sKj/NZIm5z6PlfRyus+SdL5kLpf0+RZgU6Ad2XSvQjsBXFcYRZH0SP4+ZmZmZmbVqFUEKUldu2T1AT4PfBm4WNJawNeBRRExBBgCfEPS5ql+O+DR1M6ZRfe4PneP6wFSexOAkRGxHdno1AmSOqQ6342IgcDewNIyn6Ud8Ot0nxXmXeVzuUTEi6n42IgYDNQAJ0laP5W/AwxOQdk21LGzl5mZmZlZNWlNQUpd/hIRH0fEM8BzwFbAPsBRKTfJI8D6QP9UvzPwViPa3xJ4PiL+lT5fAeyeyl+NiGkAEbE4Ij5KdUamUZJphdGdIp2A90qUF+dyKThJ0izgYbKtlPvnzt0J7Ascy8q7fn1ixTwpixp4ZDMzMzOz5tMWgpTi0YMgy1tyYmFUJCI2j4jCjlibAy81ov26cqCoxL0Lrk+jJF8j2+64WC/glRLlxblckDScbJRmaBqxeQxYK3fNVWQBykBgel0PsWKelK51VTMzMzMza3ZtIUg5VNIakvoCnwWeJhtdOEFSewBJW0haR5KAQ4BJjWj/KaCPpH7p85HAlFTeS9KQdI91JRVvVPAWRZsXSOpBlo3+kRL3WiGXS+pvV2BhRLwraStg5/wFEfE6sBC4oRHPZGZmZmZWMW1hd6+nyYKGDYHjI+I9SZeSrVWZkX7RfwM4EPgV2dSo3pI+Jsv43inlOCkptXcMcEMKQqYBF0fEB5JGAr+T1IlsPcre6bKDJQ0im75VnGX+AWBsRLxazz0LuVxOAP4EHC9pdnrWh0vUPw6yBfp1tWlmZmZmVi1adZ6UFFxMioiJjag/NiJeyJV9B5gbEZOboYtVyXlSzMzMzKwlOE9KeS4iG1XJuxNocCW5pE2Bn5MtmF8bGN6YBIrNJe0+dgOwEXBvRJzW0DXPLlzCQTc+0Ox9MzMzM7PKuvmQYZXuQkmtOkiJiFGNrL/SOpC0K1i9UiBwLXA6MCWqaHgqIt4D9q90P8zMzMzMytUWFs43OUnflzQ3/XyPLMt7J+BCYI6kX+XqPpQSPT4u6ZBUtpmke1IiyXvSKAz1JJ9cIQGkpAtziSRfSIvt8/2blHb9QtKSXPn9khqzKYCZmZmZWYtzkNJIkgYDxwA7ke2k9Q2yhJC9gT2AQcAQSQcCRMTQiNgBOBkYk5q5ELgyIrYHrgEuyN2iDysnn2yKfn+ZbCcwMzMzM7Oq5iCl8YYBN0fEOxGxBLiJbIvfOyPijZSw8RqyhI5I2kDS48CNZGtWAIYCf07HV6U2C0oln4TlCSBnAiOL+nSfpFmSrk47ia0g7WB2OnBOXQ+VT+b4/uK3y3sTZmZmZmbNwEFK45VK3titrsoRMT8iBpBluT+hrmp1HOc/X19IPglcX1SnMIITZHlaih0GTAZeq6efnyRz7NilW13VzMzMzMyanYOUxpsKHChpbUnrAAeR5WHZU1IPSe3IgoIpktaS1DFd9x6wbTp+EPhqOj6cLDdKQankkw1Ki/XfAjoUnVqDbKrZuY15SDMzMzOzSmnVu3s1h4iYkfKpPJqKLk3JFceSBTDLgL9GxK2SNgNuTdOt1gS+l645CbhM0qlkWx4fk7tFqeSTDXVrUko+uQQ4kywhZUEnYGJEvF1GOwD0Xa9z1W5HZ2ZmZmatX6tO5ri6aWzyyeayYb/tY+S4v1ayC2ZmZmbWAi44aJOK3r+uZI6e7rUakeSRLzMzMzNr9fxLb3V5FviZpG8CC4DpwH5ka1h2BW6TNBn4DdA51RkVEa+mNSy/B3oC7wLfiIin0ujMYqAG+AxwWqVHaszMzMzM6uMgpUpIqgEOAXYg+15mkAUpAN0i4vOS2pOtVzkgIt6QNJJsW+NjgfFka1iekbQT8AeyJJMAG5Ftc7wVcBvgIMXMzMzMqpaDlOoxDLg1IpYCSLo9d66w5fCWZDuE3Z0WwbcDXpXUGdgFuCG3OL5j7vpbIuJj4AlJG5a6uaTRwGiAdXv2bpIHMjMzMzNbFQ5Sqkd9W2+9k6vzeEQMXeFCqQvwdsqhUsr7Dd0nIsaTjcawYb/tvZuCmZmZmVWMF85XjweA/VNulc7Al0vUeRroKWkogKT2kgZExGLgeUmHpnJJGthiPTczMzMza0IeSakSETFN0m3ALODfQC2wqKjOB5JGABdI6kr2/f0WeJwsKeRFks4A2gPXpbYabZNuHSq+HZ2ZmZmZtV3Ok1JFJHWOiCWS1iZLDDk6Ima0dD9qamqitra2pW9rZmZmZm1MXXlSPJJSXcZL2gZYC7iiuQIUSWtGxEd1nX974UfcNHFBc9zazMzMzKrIwSN6VLoLJXlNSpWQ1Af4HNkUrQ+AwZLWlnSmpGmS5koar7R9l6TJkn4r6cF0bsdUvo6ky9I1j0k6IJWPknRD2jXsrso8pZmZmZlZwxykVJctgfERsT1ZAsZvARdGxJCI2BboRJbcsWCdiNgl1bsslZ0O3BsRQ4A9gHGS1knnhgJHR8SemJmZmZlVKQcp1eXFiPhnOr6aLHfKHpIekTSHLDnjgFz9awEiYirQRVI3YB/gh5JmApPJpo5tmurfHRFvlbqxpNGSaiXVLlr8ZtM+lZmZmZlZI3hNSnUp3sUgyDLH10TEi5LGkgUd9dUXcEhEPJ0/kbLQv0Md8nlS+vUd5N0UzMzMzKxiPJJSXTYt5EABDiPLnQKwIOVOGVFUfySApGHAoohYBNwJnJhbu7JD83fbzMzMzKzpeCSlujwJHC3pEuAZ4CJgPWAO8AIwraj+QkkPAl2AY1PZ2WS5U2anQOUFVlzH0qBu661ZtTs9mJmZmVnr5zwp9ZA0imyq1Xda4F59gElpgXw59ScDYyKiyROaOE+KmZmZmbUE50mxsr274CMeu3R+pbthZmZmZs1sh+M2qHQXSqrKNSmS+kgKScenz+0kvSxpgqT9025Xj0n6h6QNU52xksak4x9KujxXfpWkeyU9I+kbqVySxqUcI3MkFdZ3tJf0F0mPAQcB20p6WNI/JfVMdSZLqknHP5O0JB0PlzQp9xxj0mJ3JH0j5S6ZJenGlFWe9EwjIuKFiNg29adPOneUpNnpmqtS2WaS7gG6A7+StGmunefT9bMlbZvKB6X+z5Z0s6T1mut7MzMzMzNrClUZpCTzgAPT8b7Ai+n4AWDniNgBuA44LX+RpKOA3YBv5Iq3B75MlifkTEm9gIOBQcBAYG+yfCIbkS1Gfy+1/yzZjlm7ANcDPyy61wbAXmU+z00p38lAsrUnX6+vsqQBZDlP9kzXfDeduhC4MuVSuQa4IHfZqWm62FSy7YoBrgR+kOrPAc4qs79mZmZmZhVRzdO93gfmpV/WjyTLG1IDbAxcnwKKDsDzuWv2JvvlfKeI+ChXfmtELAWWSroP2JEsB8m1EbEMeF3SFGBI+vlHum420CEiPk6jF5cU9fHHwDmkfCXJbilHCUBP4I/peFtJPwO6AZ3JduEqGCfpjHTcN/25JzAxIhYA5PKbDCULsACuAs4taucXQEdgJ0ldgW4RMSWdvwK4gRIkjQZGA3ym+8alqpiZmZmZtYhqHkkBuJxspGRN4LVU9juyLOzbAd9kxbwhnwWOAH5T2II3qSufSCl1lRef6wNsGxG3F9W5PyIGRcQg4Pxc+QTgO6nfPynq96m5a57N3aucXQ3ydU6NiP7AT9M9yhYR4yOiJiJq1lt3/cZcamZmZmbWpKo6SImI6cAGZMFKQVfg5XR8dNEl4yPiL2SjK/npXgdIWkvS+sBwsq18pwIj03qXnsDuwKNALdmIDGTTxAZIWoNsWld+C+CzaNzUqXWBVyW1Bw4vo/49wP+mPiOpeyp/EPhqOj6c5blU8hYDPVLelIWSdkvlRwJTStQ3MzMzM6sa1TzdC4CI+CKApEIiw7HADZJeBh4GNi9x2SnAQ5IKoxyPAn8FNgXOjohXJN1MNnVqFtloxGkR8Zqk64AD05StF9L1D6Y6B+Xu8VJETG3Eo/wYeAT4N9nakHXrqxwRj0v6OTBF0jLgMWAUcBJwmaRTgTeAY3KXFaaNBXBcKjsauDgt1H+uqL6ZmZmZWdVp9XlS0u5aSyLivFW4dhQtlCelmjhPipmZmZm1BOdJsbJ9+Pr7vHbevEp3w8zMzMya2WfG9Kt0F0pq9UFKRIz9FNdOIFvwbmZmZmZmLaSqF843B0nfTwkP50r6XkocuVTSzPRzZar3gqRfSXo0/fRL5Q0mk0yfJ0kano6X5MrvLyR8LCRyTMfDc+X5xJR7KUtsWUgeuSz1c56kawu7mEm6RdJ0SY+n7YQL9/u6pKfSNYsKfTIzMzMzq1atfiQlT9JgsoXjO5Ft8fsI2W5Xz6btf4stjogdU4LI3wL7sTyZZEg6jmyL5FPKvP+XyXYnW5SKPqb+LY8h20EsP/dqaUQMktSJbBezbsBC4NiIeCuVT5N0Y0S8CfwSGBAR8wtBUB19+yRPSu9uvcp5HDMzMzOzZtHWRlKGATdHxDsRsQS4iSw7fV2uzf05NB1vDNwpaQ5wKjAgV//kwohMcbtpxON0suSPBS8BO9R1c0mHkG17/HKuuFNq/0VgUkQsTOUnSZpFtuPZJkD/VP4xDewkBivmSVm/c/eGqpuZmZmZNZu2FqQ0NGpRLEoc15dM8vxcUsb7i9o6DJjM8qSUAH8gyww/G7i0qH47slGaXxSVL03tfwboK2mXNIVrb2BoRAwk26640K8TgAclzaX+gMzMzMzMrCq0tSBlKlkOlLUlrUOW96Q4mMgbmfvzoXRcXzLJuqwBnAycmy+MiNciYq+I2J7leU0KjgD+GhELSjUYER8B7wI9Up8WRsS7krYCds5VfYUsF8xA6n9WMzMzM7Oq0KbWpETEDEkTyJI7QjZ6sbDuK+go6RGyIOOwVDaWhpNJFusETIyIt9M693JsCJxfqq003as98DhwB9kI0fFpRObp1C9StvoLgK9ExLJy791+w45Vux2dmZmZmbV+rT6Z46qS9AJZIseSIxmt2cBNt4y7xlxS6W6YmZmZWTPb8KThFb1/Xckc29p0LzMzMzMzq3IOUuoQEX2qdRRF0hEpd8tMSZdIaidpH0kPSZoh6QZJnVPdwZKmpBwqd0raqNL9NzMzMzOrj4OU1YykrckW8u+advlaBhwOnAHsHRGfA2qB70tqT7Yb2YiIGAxcBvy8Ih03MzMzMytTm1o430rsBQwmS9gI2aL8HYE+wD9TWQey3ci2BLYF7k7l7YBXSzWaT+a48XobNmf/zczMzMzq5SBl9SPgioj40ScF0v7A1yLisBUqStsBj0fEUBoQEeOB8ZAtnG/aLpuZmZmZlc/TvVY/9wAjJG0AIKk7MBvYVVK/VLa2pC3ItiPuKWloKm8vaUCF+m1mZmZmVhaPpKxmIuIJSWcAd0laA/gQ+DYwCrhWUsdU9YyI+JekEcAFkrqSfd+/JcuvUqf2G6xb8e3ozMzMzKztcp4UW4mk/5KNwljb0wOoyl3trEX4+2/b/P23Xf7u27ZKf/+bRUTP4kKPpFgpT5dKqmOtn6Raf/dtl7//ts3ff9vl775tq9bv32tSzMzMzMysqjhIMTMzMzOzquIgxUoZX+kOWMX4u2/b/P23bf7+2y5/921bVX7/XjhvZmZmZmZVxSMpZmZmZmZWVRyktGGS9pX0tKR5kn5Y4rwkXZDOz5b0uUr005peGd/94ek7ny3pQUkDK9FPax4Nff+5ekMkLUv5lqwVKOe7lzRc0kxJj0ua0tJ9tOZTxn/7u0q6XdKs9P0fU4l+WtOTdJmk+ZLm1nG+6n7nc5DSRklqB/we+CKwDXCYpG2Kqn0R6J9+RgMXtWgnrVmU+d0/D3w+IrYHzqZK56ta45X5/Rfq/Qq4s2V7aM2lnO9eUjfgD8BXImIAcGhL99OaR5n/7n8beCIiBgLDgV9L6tCiHbXmMgHYt57zVfc7n4OUtmtHYF5EPBcRHwDXAQcU1TkAuDIyDwPdJG3U0h21Jtfgdx8RD0bEwvTxYWDjFu6jNZ9y/t0HOBG4EZjfkp2zZlXOd/814KaI+A9ARPj7bz3K+f4DWFeSgM7AW8BHLdtNaw4RMZXs+6xL1f3O5yCl7eoNvJj7/FIqa2wdW/009nv9OvD3Zu2RtaQGv39JvYGDgItbsF/W/Mr5d38LYD1JkyVNl3RUi/XOmls53/+FwNbAK8Ac4LsR8XHLdM8qrOp+53PG+bZLJcqKt3orp46tfsr+XiXtQRakDGvWHllLKuf7/y3wg4hYlv2FqrUS5Xz3awKDgb2ATsBDkh6OiH81d+es2ZXz/X8BmAnsCfQF7pZ0f0Qsbua+WeVV3e98DlLarpeATXKfNyb7m5PG1rHVT1nfq6TtgUuBL0bEmy3UN2t+5Xz/NcB1KUDpAXxJ0kcRcUuL9NCaS7n/3V8QEe8A70iaCgwEHKSs/sr5/o8BfhlZfop5kp4HtgIebZkuWgVV3e98nu7Vdk0D+kvaPC2K+ypwW1Gd24Cj0o4POwOLIuLVlu6oNbkGv3tJmwI3AUf6b1BbnQa//4jYPCL6REQfYCLwLQcorUI5/92/FdhN0pqS1gZ2Ap5s4X5a8yjn+/8P2SgakjYEtgSea9FeWqVU3e98HklpoyLiI0nfIdu5px1wWUQ8Lun4dP5i4G/Al4B5wLtkf8Niq7kyv/szgfWBP6S/Tf8oImoq1WdrOmV+/9YKlfPdR8STku4AZgMfA5dGRMktS231Uua/+2cDEyTNIZv+84OIWFCxTluTkXQt2Y5tPSS9BJwFtIfq/Z3PGefNzMzMzKyqeLqXmZmZmZlVFQcpZmZmZmZWVRykmJmZmZlZVXGQYmZmZmZmVcVBipmZmZmZVRUHKWZmZmZmVlUcpJiZmZmZWVVxkGJmZmZmZlXl/wP7fPrPvfXofQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot word frequency distribution\n",
    "words = []\n",
    "for i in (dd.filtered_text.values):\n",
    "    wor = i.split(' ')\n",
    "    for j in wor:   \n",
    "        words.append(j)\n",
    "        \n",
    "c = Counter(words)\n",
    "most = c.most_common()\n",
    "x, y= [], []\n",
    "x1, y1= [], []\n",
    "\n",
    "for word,count in most[:15]:\n",
    "        x.append(word)\n",
    "        y.append(count)\n",
    "        \n",
    "for word,count in most[-15:]:\n",
    "        x1.append(word)\n",
    "        y1.append(count)  \n",
    "        \n",
    "fig, ax = plt.subplots(nrows=2, figsize=(12,5))\n",
    "ax[0].set(title='Word frequency')\n",
    "sns.barplot(x=y,y=x, ax=ax[0])\n",
    "sns.barplot(x=y1,y=x1, ax=ax[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560e590",
   "metadata": {},
   "source": [
    "From the histogram above, you can see that some words occur in our text more than 1600 times, but some of them occur only once. Therefore I just kept the ones that appear more than 150 times and less than 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246b43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave those that occur more than 150 and less than 1000 times throughout the text.\n",
    "words =[]\n",
    "for i in most:\n",
    "    if i[1]>150 and i[1]<1000:\n",
    "        words.append(i)\n",
    "\n",
    "def filter_tokens2(tokens):\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token in [i[0] for i in words]:\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "filtered_text2 = []\n",
    "for i in df.filtered_text:\n",
    "    wrds = i.split(' ')\n",
    "    filtered_text2.append([i for i in filter_tokens2(wrds) if i!=''])\n",
    "    \n",
    "    \n",
    "df['filtered_text2'] = [' '.join(i)for i in filtered_text2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629655b3",
   "metadata": {},
   "source": [
    "The remaining words were then summed by the year and month of the publication date,  then TF-IDF was used to vectorize them. As a result,  a vector with a size of 198 was obtained for each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c580573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>filtered_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>время февраль глава страна время привести новы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>нацбанк внутренний инфляционный перспектива ин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>нацбанк инфляционный программа экономический в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>нацбанк должен курс бизнес решение прошлый сит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>нацбанк казахстан россия политика страна казах...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month                                     filtered_text2\n",
       "0  2015      2  время февраль глава страна время привести новы...\n",
       "1  2015      5  нацбанк внутренний инфляционный перспектива ин...\n",
       "2  2015      9  нацбанк инфляционный программа экономический в...\n",
       "3  2015     10  нацбанк должен курс бизнес решение прошлый сит...\n",
       "4  2016      3  нацбанк казахстан россия политика страна казах..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 3)\n"
     ]
    }
   ],
   "source": [
    "#  summarize texts by year and month of published date\n",
    "dd = df[['year', 'month', 'filtered_text2']].groupby(['year', 'month'], as_index=False).sum()\n",
    "display(dd.head())\n",
    "print(dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6e55c84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_mat = vectorizer.fit_transform(dd.filtered_text2)\n",
    "\n",
    "dd['vector'] = [i for i in tfidf_mat.toarray()]\n",
    "dd.vector.values[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d815a",
   "metadata": {},
   "source": [
    "## 2. Picking the target value\n",
    "\n",
    "The target values are changes in inflation and the dollar exchange rate by months.\n",
    "\n",
    "Information on changes in inflation was downloaded from the website https://fin-plus.ru/info/inflation_index/kazakhstan/. \n",
    "\n",
    "Information about dollar exchange rate was downloaded from the official website of the National Bank of Kazakhstan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00962787",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation = pd.read_excel('inflation2.xlsx')\n",
    "inflation.columns=['year', 1,2,3,4,5,6,7,8,9,10,11,12, 'total']\n",
    "\n",
    "course = pd.read_excel('courses.xlsx')\n",
    "course['year'] = course.Date.apply(lambda x: int(x.split('.')[-1]))\n",
    "course['month'] = course.Date.apply(lambda x: int(x.split('.')[1]))\n",
    "cs = course[['year','month', 'USD']].groupby(by=['year','month'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78d2e7",
   "metadata": {},
   "source": [
    "I collected vectors in the range of half a year and took inflation and dollar exchange rate of the next month of the range as the target value. As a consequence, a dataframe containing 56 records was produced; the vector size for each record is 1188(198*6): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09a75bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inflation(year, month, l):\n",
    "    month += l\n",
    "    if month>12:\n",
    "        month -= 12\n",
    "        year +=1\n",
    "    try:\n",
    "        return inflation[inflation.year == year].loc[:, month].values[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def find_course(year, month, l):\n",
    "    month += l\n",
    "    if month>12:\n",
    "        month -= 12\n",
    "        year +=1\n",
    "    try:\n",
    "        return cs[(cs.year == year)&(cs.month == month)].USD.values[0]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d36a5a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month range</th>\n",
       "      <th>months</th>\n",
       "      <th>vector</th>\n",
       "      <th>inflation</th>\n",
       "      <th>USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1-6</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>186.759677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>2-7</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.019892110175782046, 0....</td>\n",
       "      <td>0.3</td>\n",
       "      <td>206.988710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3-8</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>258.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>4-9</td>\n",
       "      <td>[5, 9]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>275.458387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5-10</td>\n",
       "      <td>[5, 9, 10]</td>\n",
       "      <td>[[0.0, 0.028069912810058183, 0.010375634641849...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>302.882333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month range      months  \\\n",
       "0  2015         1-6      [2, 5]   \n",
       "1  2015         2-7      [2, 5]   \n",
       "2  2015         3-8         [5]   \n",
       "3  2015         4-9      [5, 9]   \n",
       "4  2015        5-10  [5, 9, 10]   \n",
       "\n",
       "                                              vector  inflation         USD  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0.1  186.759677  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.019892110175782046, 0....        0.3  206.988710  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        1.0  258.336667  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        5.2  275.458387  \n",
       "4  [[0.0, 0.028069912810058183, 0.010375634641849...        3.7  302.882333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 6)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for y in dd.year.unique():\n",
    "    for m in range(1,8):\n",
    "        months_range = [j for j in range(m, m+6)]\n",
    "        range_m = str(months_range[0])+'-'+str(months_range[-1])\n",
    "\n",
    "        \n",
    "        d = dd[(dd.year==y)&(dd.month.isin(months_range))].loc[:45]\n",
    "        inf =  find_inflation(y, months_range[-1], 1)\n",
    "        crs = find_course(y, months_range[-1], 1)\n",
    "        vectors = list()\n",
    "\n",
    "        for i in months_range:\n",
    "            if i in d.month.values:\n",
    "                vectors.append(list(d[d.month==i]['vector'].values[0]))\n",
    "            else:\n",
    "                vectors.append(list(np.zeros(198)))\n",
    "\n",
    "        if len(df2)==0:\n",
    "            df2 = pd.DataFrame({'year':[int(y)],\n",
    "                                'month range':[range_m],\n",
    "                                'months':[d.month.values],\n",
    "                                'vector': [vectors] ,\n",
    "                                'inflation':[inf],\n",
    "                                'USD': [crs]\n",
    "                               })\n",
    "        else:\n",
    "            df2.loc[len(df2.index)] = [int(y),range_m, d.month.values, vectors, inf, crs] \n",
    "            \n",
    "\n",
    "\n",
    "df2.to_csv('data4.csv')\n",
    "display(df2.head())\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e945ed",
   "metadata": {},
   "source": [
    "## 3. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f4264",
   "metadata": {},
   "source": [
    "**Dependent Variable:** changes in inflation , dollar exchange rate\n",
    "\n",
    "**Independent Variable:** TF-IDF vector of text.\n",
    "\n",
    "I took month ranges \"1-6,\" \"2-7,\" \"3-8,\" \"4-9,\" and \"5-10\" for the train set and the remainder for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "753fb3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer().fit([df2.USD.loc[:49].values])\n",
    "df2['scale']=list(norm.transform([df2.USD.loc[:49].values])[0])+[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "\n",
    "x = ['1-6', '2-7', '3-8', '4-9', '5-10']\n",
    "train = df2[df2['month range'].isin(x)].loc[:49]\n",
    "test  = df2[~df2['month range'].isin(x)].loc[:49]\n",
    "\n",
    "X_train= train.vector\n",
    "y_train = train.inflation\n",
    "y_train2 = train.scale\n",
    "\n",
    "X_test= test.vector\n",
    "y_test = test.inflation\n",
    "y_test2 = test.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cadfde7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shaped = np.array([np.array(i).flatten() for i in X_train ], dtype=float)\n",
    "X_test_shaped = np.array([np.array(i).flatten() for i in X_test ], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7ec8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluate(true, predicted):  \n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "\n",
    "    print('R-squared:', np.round(r2_square,5))\n",
    "    print('MSE:', np.round(mse,3))\n",
    "    print('RMSE:', np.round(rmse,3))\n",
    "    print('MAE:', np.round(mae,3))\n",
    "    \n",
    "    return {'r2':r2_square , 'mse': mse, 'rmse':   rmse, 'mae' : mae }\n",
    "\n",
    "\n",
    "\n",
    "# The function saves results of model\n",
    "m, r_r2, r_mse, r_rmse, r_mae, s_r2, s_mse, s_rmse, s_mae= [],[],[],[],[],[],[],[],[]\n",
    "\n",
    "def save_results(name, r, s, i=0,new=False):\n",
    "    if new:\n",
    "        m.append([])\n",
    "        r_r2.append([])\n",
    "        r_mse.append([])\n",
    "        r_rmse.append([])\n",
    "        r_mae.append([])\n",
    "        \n",
    "        s_r2.append([])\n",
    "        s_mse.append([])\n",
    "        s_rmse.append([])\n",
    "        s_mae.append([])\n",
    "\n",
    "    m[i].append(name)\n",
    "    r_r2[i].append(r['r2'])\n",
    "    r_mse[i].append(r['mse'])\n",
    "    r_rmse[i].append(r['rmse'])\n",
    "    r_mae[i].append(r['mae'])\n",
    "\n",
    "    s_r2[i].append(s['r2'])\n",
    "    s_mse[i].append(s['mse'])\n",
    "    s_rmse[i].append(s['rmse'])\n",
    "    s_mae[i].append(s['mae'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd46a97",
   "metadata": {},
   "source": [
    "### 3.1 target = inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91484730",
   "metadata": {},
   "source": [
    "#### XGBoost Regressor, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5583816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.99985\n",
      "MSE: 0.0\n",
      "RMSE: 0.012\n",
      "MAE: 0.003\n",
      "\n",
      "Test:\n",
      "R-squared: -3.40679\n",
      "MSE: 0.215\n",
      "RMSE: 0.464\n",
      "MAE: 0.374\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regressor\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_shaped, y_train.values)\n",
    "\n",
    "print('Train:') \n",
    "r = print_evaluate(y_train, model.predict(X_train_shaped))\n",
    "print('\\nTest:') \n",
    "s = print_evaluate(y_test, model.predict(X_test_shaped))\n",
    "\n",
    "save_results('Standard XGBRegressor', r, s, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a634539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.99986\n",
      "MSE: 0.0\n",
      "RMSE: 0.012\n",
      "MAE: 0.003\n",
      "\n",
      "Test:\n",
      "R-squared: -1.52039\n",
      "MSE: 0.123\n",
      "RMSE: 0.351\n",
      "MAE: 0.27\n"
     ]
    }
   ],
   "source": [
    "parameters = {'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [3,4,5],\n",
    "    \n",
    "              'subsample': [0.7, 0.8],\n",
    "              'colsample_bytree': [0.6, 0.7],\n",
    "              'n_estimators': [ 800, 900, 1200 ]}\n",
    "\n",
    "xgb_grid = GridSearchCV(XGBRegressor(),\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 5,scoring='r2',\n",
    "                        verbose=True)\n",
    "\n",
    "np.random.seed(200)\n",
    "xgb_grid.fit(X_train_shaped, y_train)\n",
    "\n",
    "print('Train:') \n",
    "r = print_evaluate(y_train, xgb_grid.predict(X_train_shaped))\n",
    "print('\\nTest:') \n",
    "s = print_evaluate(y_test, xgb_grid.predict(X_test_shaped))\n",
    "save_results('XGBRegressor with GridSearch', r, s, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264998f",
   "metadata": {},
   "source": [
    "#### RandomForest Regressor, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61537585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.7933\n",
      "MSE: 0.199\n",
      "RMSE: 0.446\n",
      "MAE: 0.211\n",
      "\n",
      "Test:\n",
      "R-squared: -1.81811\n",
      "MSE: 0.138\n",
      "RMSE: 0.371\n",
      "MAE: 0.294\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X_train_shaped, y_train)\n",
    "\n",
    "\n",
    "print('Train:')    \n",
    "r =print_evaluate(y_train, random_forest.predict(X_train_shaped))\n",
    "\n",
    "print('\\nTest:')    \n",
    "s = print_evaluate(y_test,random_forest.predict(X_test_shaped))\n",
    "\n",
    "save_results('Standard Random Forest', r, s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d63efcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.80181\n",
      "MSE: 0.191\n",
      "RMSE: 0.437\n",
      "MAE: 0.213\n",
      "\n",
      "Test:\n",
      "R-squared: -1.62096\n",
      "MSE: 0.128\n",
      "RMSE: 0.358\n",
      "MAE: 0.277\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "            'max_depth': range(5,8),\n",
    "            'n_estimators': [10, 100, 200],\n",
    "            'max_features': np.arange(188, 1188+500, 500)\n",
    "            }\n",
    "\n",
    "rfc_gs = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                      param_grid=param_grid, cv=5, \n",
    "                      scoring='r2', verbose=0, n_jobs=-1)\n",
    "\n",
    "\n",
    "np.random.seed(200)\n",
    "rfc_gs.fit(X_train_shaped, y_train)\n",
    "\n",
    "print('Train:')    \n",
    "r =print_evaluate(y_train, rfc_gs.predict(X_train_shaped))\n",
    "\n",
    "print('\\nTest:')    \n",
    "s = print_evaluate(y_test, rfc_gs.predict(X_test_shaped))\n",
    "save_results('Random Forest with GridSearch', r, s, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2831e",
   "metadata": {},
   "source": [
    "#### RFE with XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b83238a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.99981\n",
      "MSE: 0.0\n",
      "RMSE: 0.014\n",
      "MAE: 0.004\n",
      "\n",
      "Test:\n",
      "R-squared: -1.44348\n",
      "MSE: 0.119\n",
      "RMSE: 0.345\n",
      "MAE: 0.272\n"
     ]
    }
   ],
   "source": [
    "# RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "model = XGBRegressor()\n",
    "n_features_to_select = 35\n",
    "\n",
    "rfe = RFE(model, n_features_to_select=n_features_to_select)\n",
    "rfe.fit(X_train_shaped, y_train)\n",
    "\n",
    "print('Train:')\n",
    "rfe_r = print_evaluate(y_train, rfe.predict((X_train_shaped)))\n",
    "print('\\nTest:')\n",
    "rfe_s = print_evaluate(y_test, rfe.predict((X_test_shaped)))\n",
    "\n",
    "save_results('RFE with XGBRegressor', rfe_r, rfe_s, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051dd260",
   "metadata": {},
   "source": [
    "#### RFE with RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8f7e5bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.85288\n",
      "MSE: 0.142\n",
      "RMSE: 0.376\n",
      "MAE: 0.179\n",
      "\n",
      "Test:\n",
      "R-squared: -1.79472\n",
      "MSE: 0.136\n",
      "RMSE: 0.369\n",
      "MAE: 0.305\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor()\n",
    "\n",
    "rfe2 = RFE(regressor, n_features_to_select=n_features_to_select)\n",
    "rfe2.fit(X_train_shaped, y_train)\n",
    "\n",
    "print('Train:')\n",
    "rfe_r2 = print_evaluate(y_train, rfe2.predict((X_train_shaped)))\n",
    "print('\\nTest:')\n",
    "rfe_s2 = print_evaluate(y_test, rfe2.predict((X_test_shaped)))\n",
    "\n",
    "save_results('RFE with Random Forest', rfe_r2, rfe_s2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fbc84",
   "metadata": {},
   "source": [
    "### 3.2 target = dollar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dfba30",
   "metadata": {},
   "source": [
    "#### XGBoost Regressor, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3f86b4e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 1.0\n",
      "MSE: 0.002\n",
      "RMSE: 0.043\n",
      "MAE: 0.012\n",
      "\n",
      "Test:\n",
      "R-squared: 0.48635\n",
      "MSE: 794.198\n",
      "RMSE: 28.182\n",
      "MAE: 24.426\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_train_shaped, y_train2.values)\n",
    "\n",
    "print('Train:') \n",
    "r = print_evaluate(y_train2, model.predict(X_train_shaped))\n",
    "print('\\nTest:') \n",
    "s = print_evaluate(y_test2, model.predict(X_test_shaped))\n",
    "\n",
    "save_results('Standard XGBRegressor', r, s, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "353cc0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 1.0\n",
      "MSE: 0.002\n",
      "RMSE: 0.043\n",
      "MAE: 0.01\n",
      "\n",
      "Test:\n",
      "R-squared: 0.6094\n",
      "MSE: 603.927\n",
      "RMSE: 24.575\n",
      "MAE: 20.127\n"
     ]
    }
   ],
   "source": [
    "xgb_grid.fit(X_train_shaped, y_train2)\n",
    "\n",
    "print('Train:') \n",
    "r = print_evaluate(y_train2, xgb_grid.predict(X_train_shaped))\n",
    "print('\\nTest:') \n",
    "s = print_evaluate(y_test2, xgb_grid.predict(X_test_shaped))\n",
    "save_results('XGBRegressor with GridSearch', r, s, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f6f7b",
   "metadata": {},
   "source": [
    "#### RandomForest Regressor, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e4f61aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.87339\n",
      "MSE: 485.105\n",
      "RMSE: 22.025\n",
      "MAE: 14.648\n",
      "\n",
      "Test:\n",
      "R-squared: 0.50723\n",
      "MSE: 761.906\n",
      "RMSE: 27.603\n",
      "MAE: 22.638\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train_shaped, y_train2)\n",
    "\n",
    "print('Train:')    \n",
    "r =print_evaluate(y_train2, random_forest.predict(X_train_shaped))\n",
    "\n",
    "print('\\nTest:')    \n",
    "s = print_evaluate(y_test2,random_forest.predict(X_test_shaped))\n",
    "\n",
    "save_results('Standard Random Forest', r, s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b54d3a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Train:\n",
      "R-squared: 0.77937\n",
      "MSE: 845.356\n",
      "RMSE: 29.075\n",
      "MAE: 22.298\n",
      "\n",
      "Test:\n",
      "R-squared: 0.6393\n",
      "MSE: 557.71\n",
      "RMSE: 23.616\n",
      "MAE: 21.677\n"
     ]
    }
   ],
   "source": [
    "rfc_gs.fit(X_train_shaped, y_train2)\n",
    "\n",
    "print('Train:')    \n",
    "r =print_evaluate(y_train2, rfc_gs.predict(X_train_shaped))\n",
    "\n",
    "print('\\nTest:')    \n",
    "s = print_evaluate(y_test2, rfc_gs.predict(X_test_shaped))\n",
    "save_results('Random Forest with GridSearch', r, s, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cd426",
   "metadata": {},
   "source": [
    "#### RFE with XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a905c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 1.0\n",
      "MSE: 0.002\n",
      "RMSE: 0.043\n",
      "MAE: 0.01\n",
      "\n",
      "Test:\n",
      "R-squared: 0.63087\n",
      "MSE: 570.744\n",
      "RMSE: 23.89\n",
      "MAE: 19.301\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, n_features_to_select=n_features_to_select)\n",
    "rfe.fit(X_train_shaped, y_train2)\n",
    "\n",
    "print('Train:')\n",
    "rfe_r = print_evaluate(y_train2, rfe.predict((X_train_shaped)))\n",
    "print('\\nTest:')\n",
    "rfe_s = print_evaluate(y_test2, rfe.predict((X_test_shaped)))\n",
    "save_results('RFE with XGBRegressor', rfe_r, rfe_s, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb5582",
   "metadata": {},
   "source": [
    "#### RFE with RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f1ac8b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.92166\n",
      "MSE: 300.172\n",
      "RMSE: 17.325\n",
      "MAE: 10.857\n",
      "\n",
      "Test:\n",
      "R-squared: 0.51987\n",
      "MSE: 742.359\n",
      "RMSE: 27.246\n",
      "MAE: 25.37\n"
     ]
    }
   ],
   "source": [
    "rfe2 = RFE(regressor, n_features_to_select=n_features_to_select)\n",
    "rfe2.fit(X_train_shaped, y_train2)\n",
    "print('Train:')\n",
    "rfe_r2 = print_evaluate(y_train2, rfe2.predict((X_train_shaped)))\n",
    "print('\\nTest:')\n",
    "rfe_s2 = print_evaluate(y_test2, rfe2.predict((X_test_shaped)))\n",
    "\n",
    "save_results('RFE with Random Forest', rfe_r2, rfe_s2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a6754a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target = inflation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_Train</th>\n",
       "      <th>r2_Test</th>\n",
       "      <th>MSE_Train</th>\n",
       "      <th>MSE_Test</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>MAE_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard XGBRegressor</th>\n",
       "      <td>0.999855</td>\n",
       "      <td>-1.520390</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.123062</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.350802</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.270168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor with GridSearch</th>\n",
       "      <td>0.999855</td>\n",
       "      <td>-3.406795</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.215169</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>0.463863</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.374157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Random Forest</th>\n",
       "      <td>0.793299</td>\n",
       "      <td>-1.818106</td>\n",
       "      <td>0.198963</td>\n",
       "      <td>0.137598</td>\n",
       "      <td>0.446052</td>\n",
       "      <td>0.370943</td>\n",
       "      <td>0.210991</td>\n",
       "      <td>0.293902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Random Forest</th>\n",
       "      <td>0.801806</td>\n",
       "      <td>-1.620963</td>\n",
       "      <td>0.190774</td>\n",
       "      <td>0.127973</td>\n",
       "      <td>0.436777</td>\n",
       "      <td>0.357732</td>\n",
       "      <td>0.213206</td>\n",
       "      <td>0.276651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE with XGBRegressor</th>\n",
       "      <td>0.999807</td>\n",
       "      <td>-1.443478</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.119307</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.345408</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.272356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE with Random Forest</th>\n",
       "      <td>0.852878</td>\n",
       "      <td>-1.794715</td>\n",
       "      <td>0.141614</td>\n",
       "      <td>0.136456</td>\n",
       "      <td>0.376316</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>0.178765</td>\n",
       "      <td>0.305398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              r2_Train   r2_Test  MSE_Train  MSE_Test  \\\n",
       "Standard XGBRegressor         0.999855 -1.520390   0.000139  0.123062   \n",
       "XGBRegressor with GridSearch  0.999855 -3.406795   0.000140  0.215169   \n",
       "Standard Random Forest        0.793299 -1.818106   0.198963  0.137598   \n",
       "Standard Random Forest        0.801806 -1.620963   0.190774  0.127973   \n",
       "RFE with XGBRegressor         0.999807 -1.443478   0.000186  0.119307   \n",
       "RFE with Random Forest        0.852878 -1.794715   0.141614  0.136456   \n",
       "\n",
       "                              RMSE_Train  RMSE_Test  MAE_Train  MAE_Test  \n",
       "Standard XGBRegressor           0.011804   0.350802   0.003095  0.270168  \n",
       "XGBRegressor with GridSearch    0.011820   0.463863   0.003307  0.374157  \n",
       "Standard Random Forest          0.446052   0.370943   0.210991  0.293902  \n",
       "Standard Random Forest          0.436777   0.357732   0.213206  0.276651  \n",
       "RFE with XGBRegressor           0.013628   0.345408   0.004151  0.272356  \n",
       "RFE with Random Forest          0.376316   0.369400   0.178765  0.305398  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target = dollar exchange rate:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_Train</th>\n",
       "      <th>r2_Test</th>\n",
       "      <th>MSE_Train</th>\n",
       "      <th>MSE_Test</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>MAE_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard XGBRegressor</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486345</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>794.197665</td>\n",
       "      <td>0.042944</td>\n",
       "      <td>28.181513</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>24.426355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor with GridSearch</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609405</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>603.926652</td>\n",
       "      <td>0.042562</td>\n",
       "      <td>24.574919</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>20.127375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Random Forest</th>\n",
       "      <td>0.873394</td>\n",
       "      <td>0.507230</td>\n",
       "      <td>485.104561</td>\n",
       "      <td>761.905815</td>\n",
       "      <td>22.025089</td>\n",
       "      <td>27.602641</td>\n",
       "      <td>14.647825</td>\n",
       "      <td>22.638296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest with GridSearch</th>\n",
       "      <td>0.779374</td>\n",
       "      <td>0.639295</td>\n",
       "      <td>845.355673</td>\n",
       "      <td>557.710285</td>\n",
       "      <td>29.075001</td>\n",
       "      <td>23.615891</td>\n",
       "      <td>22.298457</td>\n",
       "      <td>21.676525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE with XGBRegressor</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>570.743727</td>\n",
       "      <td>0.042564</td>\n",
       "      <td>23.890243</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>19.301182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE with Random Forest</th>\n",
       "      <td>0.921659</td>\n",
       "      <td>0.519872</td>\n",
       "      <td>300.172005</td>\n",
       "      <td>742.358880</td>\n",
       "      <td>17.325473</td>\n",
       "      <td>27.246264</td>\n",
       "      <td>10.856798</td>\n",
       "      <td>25.370411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               r2_Train   r2_Test   MSE_Train    MSE_Test  \\\n",
       "Standard XGBRegressor          1.000000  0.486345    0.001844  794.197665   \n",
       "XGBRegressor with GridSearch   1.000000  0.609405    0.001811  603.926652   \n",
       "Standard Random Forest         0.873394  0.507230  485.104561  761.905815   \n",
       "Random Forest with GridSearch  0.779374  0.639295  845.355673  557.710285   \n",
       "RFE with XGBRegressor          1.000000  0.630866    0.001812  570.743727   \n",
       "RFE with Random Forest         0.921659  0.519872  300.172005  742.358880   \n",
       "\n",
       "                               RMSE_Train  RMSE_Test  MAE_Train   MAE_Test  \n",
       "Standard XGBRegressor            0.042944  28.181513   0.012001  24.426355  \n",
       "XGBRegressor with GridSearch     0.042562  24.574919   0.010372  20.127375  \n",
       "Standard Random Forest          22.025089  27.602641  14.647825  22.638296  \n",
       "Random Forest with GridSearch   29.075001  23.615891  22.298457  21.676525  \n",
       "RFE with XGBRegressor            0.042564  23.890243   0.010437  19.301182  \n",
       "RFE with Random Forest          17.325473  27.246264  10.856798  25.370411  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_df(i):\n",
    "    res = pd.DataFrame(index=m[i])\n",
    "    res['r2_Train'] =r_r2[i]\n",
    "    res['r2_Test'] =s_r2[i]\n",
    "\n",
    "    res['MSE_Train'] = r_mse[i]\n",
    "    res['MSE_Test'] = s_mse[i]\n",
    "\n",
    "    res['RMSE_Train'] = r_rmse[i]\n",
    "    res['RMSE_Test'] = s_rmse[i]\n",
    "\n",
    "    res['RMSE_Train'] = r_rmse[i]\n",
    "    res['RMSE_Test'] = s_rmse[i]\n",
    "\n",
    "    res['MAE_Train'] = r_mae[i]\n",
    "    res['MAE_Test'] = s_mae[i]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "print('target = inflation:')\n",
    "display(create_df(0))\n",
    "print('\\ntarget = dollar exchange rate:')\n",
    "display(create_df(1).tail(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a2996",
   "metadata": {},
   "source": [
    "By evaluating metrics, RFE with XGBoost regressior performed comparably better results. R-squared value, Mean squared error, Root mean squared error and Mean absolute error rates have been assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b0d8a",
   "metadata": {},
   "source": [
    "## 4. Building network\n",
    "\n",
    "I have created a network with 1188(198*6) input units, a hidden layer with 256 units and a ReLU activation, then a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and dropout in between to avoid overfitting. Finally an output layer with a sigmoid activation. Network uses ADAM optimizing, and mean_absolute_error loss with 0.002 learning rate\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48052114",
   "metadata": {
    "id": "cuOTXrgVG3A3"
   },
   "outputs": [],
   "source": [
    "# Creating model using the Sequential in tensorflow\n",
    "seed = 200\n",
    "np.random.seed(seed)\n",
    "def build_model_using_sequential():\n",
    "    model = Sequential([\n",
    "#      Input\n",
    "        Dense(256, kernel_initializer='normal', activation='relu', input_dim=1188 ),\n",
    "        Dropout(0.2),\n",
    "#      Hidden\n",
    "        Dense(128, kernel_initializer='normal', activation='relu'),\n",
    "        Dropout(0.2),  \n",
    "#      Hidden\n",
    "        Dense(64, kernel_initializer='normal', activation='relu'),\n",
    "#      Output\n",
    "        Dense(1, kernel_initializer='normal', activation='sigmoid')\n",
    "      ])\n",
    "    return model\n",
    "# build the model\n",
    "model = build_model_using_sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b604b",
   "metadata": {},
   "source": [
    "### 4.1 target = inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33fdacbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "D66HTfDEHEuR",
    "outputId": "3266b4ae-4d65-4df9-9a08-6201ee79879c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.5961 - mean_absolute_error: 0.5961 - val_loss: 0.6247 - val_mean_absolute_error: 0.6247\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5900 - mean_absolute_error: 0.5900 - val_loss: 0.6177 - val_mean_absolute_error: 0.6177\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5851 - mean_absolute_error: 0.5851 - val_loss: 0.6107 - val_mean_absolute_error: 0.6107\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5773 - mean_absolute_error: 0.5773 - val_loss: 0.6037 - val_mean_absolute_error: 0.6037\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5718 - mean_absolute_error: 0.5718 - val_loss: 0.5962 - val_mean_absolute_error: 0.5962\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5664 - mean_absolute_error: 0.5664 - val_loss: 0.5882 - val_mean_absolute_error: 0.5882\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5600 - mean_absolute_error: 0.5600 - val_loss: 0.5797 - val_mean_absolute_error: 0.5797\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5529 - mean_absolute_error: 0.5529 - val_loss: 0.5703 - val_mean_absolute_error: 0.5703\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5457 - mean_absolute_error: 0.5457 - val_loss: 0.5600 - val_mean_absolute_error: 0.5600\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5399 - mean_absolute_error: 0.5399 - val_loss: 0.5492 - val_mean_absolute_error: 0.5492\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5296 - mean_absolute_error: 0.5296 - val_loss: 0.5382 - val_mean_absolute_error: 0.5382\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5185 - mean_absolute_error: 0.5185 - val_loss: 0.5265 - val_mean_absolute_error: 0.5265\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5146 - mean_absolute_error: 0.5146 - val_loss: 0.5141 - val_mean_absolute_error: 0.5141\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5073 - mean_absolute_error: 0.5073 - val_loss: 0.5015 - val_mean_absolute_error: 0.5015\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4949 - mean_absolute_error: 0.4949 - val_loss: 0.4881 - val_mean_absolute_error: 0.4881\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4897 - mean_absolute_error: 0.4897 - val_loss: 0.4742 - val_mean_absolute_error: 0.4742\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4820 - mean_absolute_error: 0.4820 - val_loss: 0.4600 - val_mean_absolute_error: 0.4600\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4723 - mean_absolute_error: 0.4723 - val_loss: 0.4459 - val_mean_absolute_error: 0.4459\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4626 - mean_absolute_error: 0.4626 - val_loss: 0.4316 - val_mean_absolute_error: 0.4316\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4619 - mean_absolute_error: 0.4619 - val_loss: 0.4174 - val_mean_absolute_error: 0.4174\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4451 - mean_absolute_error: 0.4451 - val_loss: 0.4035 - val_mean_absolute_error: 0.4035\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4362 - mean_absolute_error: 0.4362 - val_loss: 0.3905 - val_mean_absolute_error: 0.3905\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4391 - mean_absolute_error: 0.4391 - val_loss: 0.3780 - val_mean_absolute_error: 0.3780\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4165 - mean_absolute_error: 0.4165 - val_loss: 0.3656 - val_mean_absolute_error: 0.3656\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4196 - mean_absolute_error: 0.4196 - val_loss: 0.3537 - val_mean_absolute_error: 0.3537\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4161 - mean_absolute_error: 0.4161 - val_loss: 0.3424 - val_mean_absolute_error: 0.3424\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3982 - mean_absolute_error: 0.3982 - val_loss: 0.3319 - val_mean_absolute_error: 0.3319\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3917 - mean_absolute_error: 0.3917 - val_loss: 0.3224 - val_mean_absolute_error: 0.3224\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3881 - mean_absolute_error: 0.3881 - val_loss: 0.3157 - val_mean_absolute_error: 0.3157\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3922 - mean_absolute_error: 0.3922 - val_loss: 0.3122 - val_mean_absolute_error: 0.3122\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3797 - mean_absolute_error: 0.3797 - val_loss: 0.3085 - val_mean_absolute_error: 0.3085\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3677 - mean_absolute_error: 0.3677 - val_loss: 0.3064 - val_mean_absolute_error: 0.3064\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3578 - mean_absolute_error: 0.3578 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3691 - mean_absolute_error: 0.3691 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3585 - mean_absolute_error: 0.3585 - val_loss: 0.3065 - val_mean_absolute_error: 0.3065\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3554 - mean_absolute_error: 0.3554 - val_loss: 0.3072 - val_mean_absolute_error: 0.3072\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3337 - mean_absolute_error: 0.3337 - val_loss: 0.3090 - val_mean_absolute_error: 0.3090\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3471 - mean_absolute_error: 0.3471 - val_loss: 0.3095 - val_mean_absolute_error: 0.3095\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3546 - mean_absolute_error: 0.3546 - val_loss: 0.3089 - val_mean_absolute_error: 0.3089\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3270 - mean_absolute_error: 0.3270 - val_loss: 0.3088 - val_mean_absolute_error: 0.3088\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3328 - mean_absolute_error: 0.3328 - val_loss: 0.3077 - val_mean_absolute_error: 0.3077\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3199 - mean_absolute_error: 0.3199 - val_loss: 0.3069 - val_mean_absolute_error: 0.3069\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3206 - mean_absolute_error: 0.3206 - val_loss: 0.3065 - val_mean_absolute_error: 0.3065\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3193 - mean_absolute_error: 0.3193 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3058 - mean_absolute_error: 0.3058 - val_loss: 0.3094 - val_mean_absolute_error: 0.3094\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3068 - mean_absolute_error: 0.3068 - val_loss: 0.3107 - val_mean_absolute_error: 0.3107\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3072 - mean_absolute_error: 0.3072 - val_loss: 0.3113 - val_mean_absolute_error: 0.3113\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2901 - mean_absolute_error: 0.2901 - val_loss: 0.3127 - val_mean_absolute_error: 0.3127\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2754 - mean_absolute_error: 0.2754 - val_loss: 0.3099 - val_mean_absolute_error: 0.3099\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2909 - mean_absolute_error: 0.2909 - val_loss: 0.3083 - val_mean_absolute_error: 0.3083\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2742 - mean_absolute_error: 0.2742 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2722 - mean_absolute_error: 0.2722 - val_loss: 0.3045 - val_mean_absolute_error: 0.3045\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2649 - mean_absolute_error: 0.2649 - val_loss: 0.3035 - val_mean_absolute_error: 0.3035\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2586 - mean_absolute_error: 0.2586 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2679 - mean_absolute_error: 0.2679 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2453 - mean_absolute_error: 0.2453 - val_loss: 0.3017 - val_mean_absolute_error: 0.3017\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2612 - mean_absolute_error: 0.2612 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2564 - mean_absolute_error: 0.2564 - val_loss: 0.3032 - val_mean_absolute_error: 0.3032\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2525 - mean_absolute_error: 0.2525 - val_loss: 0.3049 - val_mean_absolute_error: 0.3049\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2572 - mean_absolute_error: 0.2572 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2530 - mean_absolute_error: 0.2530 - val_loss: 0.3085 - val_mean_absolute_error: 0.3085\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2571 - mean_absolute_error: 0.2571 - val_loss: 0.3096 - val_mean_absolute_error: 0.3096\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2557 - mean_absolute_error: 0.2557 - val_loss: 0.3119 - val_mean_absolute_error: 0.3119\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2459 - mean_absolute_error: 0.2459 - val_loss: 0.3137 - val_mean_absolute_error: 0.3137\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2481 - mean_absolute_error: 0.2481 - val_loss: 0.3141 - val_mean_absolute_error: 0.3141\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2504 - mean_absolute_error: 0.2504 - val_loss: 0.3134 - val_mean_absolute_error: 0.3134\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2512 - mean_absolute_error: 0.2512 - val_loss: 0.3116 - val_mean_absolute_error: 0.3116\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2500 - mean_absolute_error: 0.2500 - val_loss: 0.3101 - val_mean_absolute_error: 0.3101\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2445 - mean_absolute_error: 0.2445 - val_loss: 0.3081 - val_mean_absolute_error: 0.3081\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2531 - mean_absolute_error: 0.2531 - val_loss: 0.3080 - val_mean_absolute_error: 0.3080\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2627 - mean_absolute_error: 0.2627 - val_loss: 0.3076 - val_mean_absolute_error: 0.3076\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2403 - mean_absolute_error: 0.2403 - val_loss: 0.3081 - val_mean_absolute_error: 0.3081\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2506 - mean_absolute_error: 0.2506 - val_loss: 0.3080 - val_mean_absolute_error: 0.3080\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2459 - mean_absolute_error: 0.2459 - val_loss: 0.3069 - val_mean_absolute_error: 0.3069\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2620 - mean_absolute_error: 0.2620 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2492 - mean_absolute_error: 0.2492 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2359 - mean_absolute_error: 0.2359 - val_loss: 0.2992 - val_mean_absolute_error: 0.2992\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2400 - mean_absolute_error: 0.2400 - val_loss: 0.2967 - val_mean_absolute_error: 0.2967\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2420 - mean_absolute_error: 0.2420 - val_loss: 0.2946 - val_mean_absolute_error: 0.2946\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2425 - mean_absolute_error: 0.2425 - val_loss: 0.2929 - val_mean_absolute_error: 0.2929\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2426 - mean_absolute_error: 0.2426 - val_loss: 0.2922 - val_mean_absolute_error: 0.2922\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2475 - mean_absolute_error: 0.2475 - val_loss: 0.2920 - val_mean_absolute_error: 0.2920\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2438 - mean_absolute_error: 0.2438 - val_loss: 0.2917 - val_mean_absolute_error: 0.2917\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2435 - mean_absolute_error: 0.2435 - val_loss: 0.2926 - val_mean_absolute_error: 0.2926\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2442 - mean_absolute_error: 0.2442 - val_loss: 0.2933 - val_mean_absolute_error: 0.2933\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2543 - mean_absolute_error: 0.2543 - val_loss: 0.2942 - val_mean_absolute_error: 0.2942\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2434 - mean_absolute_error: 0.2434 - val_loss: 0.2949 - val_mean_absolute_error: 0.2949\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2497 - mean_absolute_error: 0.2497 - val_loss: 0.2950 - val_mean_absolute_error: 0.2950\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2379 - mean_absolute_error: 0.2379 - val_loss: 0.2943 - val_mean_absolute_error: 0.2943\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2484 - mean_absolute_error: 0.2484 - val_loss: 0.2942 - val_mean_absolute_error: 0.2942\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2439 - mean_absolute_error: 0.2439 - val_loss: 0.2948 - val_mean_absolute_error: 0.2948\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2484 - mean_absolute_error: 0.2484 - val_loss: 0.2962 - val_mean_absolute_error: 0.2962\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2397 - mean_absolute_error: 0.2397 - val_loss: 0.2972 - val_mean_absolute_error: 0.2972\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2396 - mean_absolute_error: 0.2396 - val_loss: 0.2988 - val_mean_absolute_error: 0.2988\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2384 - mean_absolute_error: 0.2384 - val_loss: 0.2996 - val_mean_absolute_error: 0.2996\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2417 - mean_absolute_error: 0.2417 - val_loss: 0.2998 - val_mean_absolute_error: 0.2998\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2481 - mean_absolute_error: 0.2481 - val_loss: 0.3002 - val_mean_absolute_error: 0.3002\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2411 - mean_absolute_error: 0.2411 - val_loss: 0.3009 - val_mean_absolute_error: 0.3009\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2367 - mean_absolute_error: 0.2367 - val_loss: 0.3012 - val_mean_absolute_error: 0.3012\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2392 - mean_absolute_error: 0.2392 - val_loss: 0.3010 - val_mean_absolute_error: 0.3010\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2354 - mean_absolute_error: 0.2354 - val_loss: 0.3009 - val_mean_absolute_error: 0.3009\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2445 - mean_absolute_error: 0.2445 - val_loss: 0.3009 - val_mean_absolute_error: 0.3009\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2393 - mean_absolute_error: 0.2393 - val_loss: 0.3006 - val_mean_absolute_error: 0.3006\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2473 - mean_absolute_error: 0.2473 - val_loss: 0.3001 - val_mean_absolute_error: 0.3001\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2405 - mean_absolute_error: 0.2405 - val_loss: 0.3002 - val_mean_absolute_error: 0.3002\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2431 - mean_absolute_error: 0.2431 - val_loss: 0.2995 - val_mean_absolute_error: 0.2995\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2398 - mean_absolute_error: 0.2398 - val_loss: 0.2988 - val_mean_absolute_error: 0.2988\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2396 - mean_absolute_error: 0.2396 - val_loss: 0.2981 - val_mean_absolute_error: 0.2981\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2429 - mean_absolute_error: 0.2429 - val_loss: 0.2984 - val_mean_absolute_error: 0.2984\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2324 - mean_absolute_error: 0.2324 - val_loss: 0.2985 - val_mean_absolute_error: 0.2985\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2399 - mean_absolute_error: 0.2399 - val_loss: 0.2983 - val_mean_absolute_error: 0.2983\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2417 - mean_absolute_error: 0.2417 - val_loss: 0.2979 - val_mean_absolute_error: 0.2979\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2452 - mean_absolute_error: 0.2452 - val_loss: 0.2968 - val_mean_absolute_error: 0.2968\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2427 - mean_absolute_error: 0.2427 - val_loss: 0.2948 - val_mean_absolute_error: 0.2948\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2351 - mean_absolute_error: 0.2351 - val_loss: 0.2925 - val_mean_absolute_error: 0.2925\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2335 - mean_absolute_error: 0.2335 - val_loss: 0.2903 - val_mean_absolute_error: 0.2903\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2363 - mean_absolute_error: 0.2363 - val_loss: 0.2885 - val_mean_absolute_error: 0.2885\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2370 - mean_absolute_error: 0.2370 - val_loss: 0.2877 - val_mean_absolute_error: 0.2877\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2368 - mean_absolute_error: 0.2368 - val_loss: 0.2873 - val_mean_absolute_error: 0.2873\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2408 - mean_absolute_error: 0.2408 - val_loss: 0.2872 - val_mean_absolute_error: 0.2872\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2365 - mean_absolute_error: 0.2365 - val_loss: 0.2869 - val_mean_absolute_error: 0.2869\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2870 - val_mean_absolute_error: 0.2870\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2372 - mean_absolute_error: 0.2372 - val_loss: 0.2881 - val_mean_absolute_error: 0.2881\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2438 - mean_absolute_error: 0.2438 - val_loss: 0.2897 - val_mean_absolute_error: 0.2897\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2377 - mean_absolute_error: 0.2377 - val_loss: 0.2912 - val_mean_absolute_error: 0.2912\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2389 - mean_absolute_error: 0.2389 - val_loss: 0.2927 - val_mean_absolute_error: 0.2927\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2383 - mean_absolute_error: 0.2383 - val_loss: 0.2933 - val_mean_absolute_error: 0.2933\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2944 - val_mean_absolute_error: 0.2944\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2408 - mean_absolute_error: 0.2408 - val_loss: 0.2948 - val_mean_absolute_error: 0.2948\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2365 - mean_absolute_error: 0.2365 - val_loss: 0.2954 - val_mean_absolute_error: 0.2954\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2378 - mean_absolute_error: 0.2378 - val_loss: 0.2961 - val_mean_absolute_error: 0.2961\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2399 - mean_absolute_error: 0.2399 - val_loss: 0.2964 - val_mean_absolute_error: 0.2964\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.2968 - val_mean_absolute_error: 0.2968\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2968 - val_mean_absolute_error: 0.2968\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2374 - mean_absolute_error: 0.2374 - val_loss: 0.2962 - val_mean_absolute_error: 0.2962\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2377 - mean_absolute_error: 0.2377 - val_loss: 0.2959 - val_mean_absolute_error: 0.2959\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2414 - mean_absolute_error: 0.2414 - val_loss: 0.2942 - val_mean_absolute_error: 0.2942\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2364 - mean_absolute_error: 0.2364 - val_loss: 0.2928 - val_mean_absolute_error: 0.2928\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2382 - mean_absolute_error: 0.2382 - val_loss: 0.2912 - val_mean_absolute_error: 0.2912\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2896 - val_mean_absolute_error: 0.2896\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2392 - mean_absolute_error: 0.2392 - val_loss: 0.2882 - val_mean_absolute_error: 0.2882\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2343 - mean_absolute_error: 0.2343 - val_loss: 0.2866 - val_mean_absolute_error: 0.2866\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2366 - mean_absolute_error: 0.2366 - val_loss: 0.2850 - val_mean_absolute_error: 0.2850\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2368 - mean_absolute_error: 0.2368 - val_loss: 0.2833 - val_mean_absolute_error: 0.2833\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2331 - mean_absolute_error: 0.2331 - val_loss: 0.2820 - val_mean_absolute_error: 0.2820\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.2806 - val_mean_absolute_error: 0.2806\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2398 - mean_absolute_error: 0.2398 - val_loss: 0.2800 - val_mean_absolute_error: 0.2800\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2426 - mean_absolute_error: 0.2426 - val_loss: 0.2789 - val_mean_absolute_error: 0.2789\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2438 - mean_absolute_error: 0.2438 - val_loss: 0.2782 - val_mean_absolute_error: 0.2782\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2403 - mean_absolute_error: 0.2403 - val_loss: 0.2781 - val_mean_absolute_error: 0.2781\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2370 - mean_absolute_error: 0.2370 - val_loss: 0.2780 - val_mean_absolute_error: 0.2780\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2315 - mean_absolute_error: 0.2315 - val_loss: 0.2779 - val_mean_absolute_error: 0.2779\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2409 - mean_absolute_error: 0.2409 - val_loss: 0.2785 - val_mean_absolute_error: 0.2785\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2349 - mean_absolute_error: 0.2349 - val_loss: 0.2805 - val_mean_absolute_error: 0.2805\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2348 - mean_absolute_error: 0.2348 - val_loss: 0.2827 - val_mean_absolute_error: 0.2827\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2388 - mean_absolute_error: 0.2388 - val_loss: 0.2853 - val_mean_absolute_error: 0.2853\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2350 - mean_absolute_error: 0.2350 - val_loss: 0.2882 - val_mean_absolute_error: 0.2882\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2335 - mean_absolute_error: 0.2335 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2393 - mean_absolute_error: 0.2393 - val_loss: 0.2924 - val_mean_absolute_error: 0.2924\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2412 - mean_absolute_error: 0.2412 - val_loss: 0.2936 - val_mean_absolute_error: 0.2936\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2325 - mean_absolute_error: 0.2325 - val_loss: 0.2938 - val_mean_absolute_error: 0.2938\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2401 - mean_absolute_error: 0.2401 - val_loss: 0.2932 - val_mean_absolute_error: 0.2932\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2360 - mean_absolute_error: 0.2360 - val_loss: 0.2923 - val_mean_absolute_error: 0.2923\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2336 - mean_absolute_error: 0.2336 - val_loss: 0.2907 - val_mean_absolute_error: 0.2907\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2349 - mean_absolute_error: 0.2349 - val_loss: 0.2893 - val_mean_absolute_error: 0.2893\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2380 - mean_absolute_error: 0.2380 - val_loss: 0.2882 - val_mean_absolute_error: 0.2882\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2354 - mean_absolute_error: 0.2354 - val_loss: 0.2876 - val_mean_absolute_error: 0.2876\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2349 - mean_absolute_error: 0.2349 - val_loss: 0.2880 - val_mean_absolute_error: 0.2880\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2331 - mean_absolute_error: 0.2331 - val_loss: 0.2881 - val_mean_absolute_error: 0.2881\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2365 - mean_absolute_error: 0.2365 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.2890 - val_mean_absolute_error: 0.2890\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2356 - mean_absolute_error: 0.2356 - val_loss: 0.2895 - val_mean_absolute_error: 0.2895\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2367 - mean_absolute_error: 0.2367 - val_loss: 0.2901 - val_mean_absolute_error: 0.2901\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2344 - mean_absolute_error: 0.2344 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2349 - mean_absolute_error: 0.2349 - val_loss: 0.2913 - val_mean_absolute_error: 0.2913\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2284 - mean_absolute_error: 0.2284 - val_loss: 0.2917 - val_mean_absolute_error: 0.2917\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2373 - mean_absolute_error: 0.2373 - val_loss: 0.2922 - val_mean_absolute_error: 0.2922\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2353 - mean_absolute_error: 0.2353 - val_loss: 0.2929 - val_mean_absolute_error: 0.2929\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2341 - mean_absolute_error: 0.2341 - val_loss: 0.2937 - val_mean_absolute_error: 0.2937\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2349 - mean_absolute_error: 0.2349 - val_loss: 0.2945 - val_mean_absolute_error: 0.2945\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.2954 - val_mean_absolute_error: 0.2954\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2306 - mean_absolute_error: 0.2306 - val_loss: 0.2966 - val_mean_absolute_error: 0.2966\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2376 - mean_absolute_error: 0.2376 - val_loss: 0.2969 - val_mean_absolute_error: 0.2969\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2359 - mean_absolute_error: 0.2359 - val_loss: 0.2967 - val_mean_absolute_error: 0.2967\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2359 - mean_absolute_error: 0.2359 - val_loss: 0.2957 - val_mean_absolute_error: 0.2957\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2340 - mean_absolute_error: 0.2340 - val_loss: 0.2941 - val_mean_absolute_error: 0.2941\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2923 - val_mean_absolute_error: 0.2923\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2363 - mean_absolute_error: 0.2363 - val_loss: 0.2909 - val_mean_absolute_error: 0.2909\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2322 - mean_absolute_error: 0.2322 - val_loss: 0.2894 - val_mean_absolute_error: 0.2894\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2356 - mean_absolute_error: 0.2356 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2880 - val_mean_absolute_error: 0.2880\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2880 - val_mean_absolute_error: 0.2880\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2351 - mean_absolute_error: 0.2351 - val_loss: 0.2881 - val_mean_absolute_error: 0.2881\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2324 - mean_absolute_error: 0.2324 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2362 - mean_absolute_error: 0.2362 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2326 - mean_absolute_error: 0.2326 - val_loss: 0.2882 - val_mean_absolute_error: 0.2882\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2339 - mean_absolute_error: 0.2339 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2333 - mean_absolute_error: 0.2333 - val_loss: 0.2883 - val_mean_absolute_error: 0.2883\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2325 - mean_absolute_error: 0.2325 - val_loss: 0.2882 - val_mean_absolute_error: 0.2882\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2880 - val_mean_absolute_error: 0.2880\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2404 - mean_absolute_error: 0.2404 - val_loss: 0.2889 - val_mean_absolute_error: 0.2889\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2331 - mean_absolute_error: 0.2331 - val_loss: 0.2893 - val_mean_absolute_error: 0.2893\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2895 - val_mean_absolute_error: 0.2895\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2311 - mean_absolute_error: 0.2311 - val_loss: 0.2896 - val_mean_absolute_error: 0.2896\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2338 - mean_absolute_error: 0.2338 - val_loss: 0.2900 - val_mean_absolute_error: 0.2900\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2377 - mean_absolute_error: 0.2377 - val_loss: 0.2904 - val_mean_absolute_error: 0.2904\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2330 - mean_absolute_error: 0.2330 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2315 - mean_absolute_error: 0.2315 - val_loss: 0.2909 - val_mean_absolute_error: 0.2909\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2905 - val_mean_absolute_error: 0.2905\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2336 - mean_absolute_error: 0.2336 - val_loss: 0.2897 - val_mean_absolute_error: 0.2897\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2375 - mean_absolute_error: 0.2375 - val_loss: 0.2897 - val_mean_absolute_error: 0.2897\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2342 - mean_absolute_error: 0.2342 - val_loss: 0.2897 - val_mean_absolute_error: 0.2897\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2398 - mean_absolute_error: 0.2398 - val_loss: 0.2898 - val_mean_absolute_error: 0.2898\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2375 - mean_absolute_error: 0.2375 - val_loss: 0.2902 - val_mean_absolute_error: 0.2902\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2329 - mean_absolute_error: 0.2329 - val_loss: 0.2902 - val_mean_absolute_error: 0.2902\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2336 - mean_absolute_error: 0.2336 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2332 - mean_absolute_error: 0.2332 - val_loss: 0.2907 - val_mean_absolute_error: 0.2907\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2294 - mean_absolute_error: 0.2294 - val_loss: 0.2911 - val_mean_absolute_error: 0.2911\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.2909 - val_mean_absolute_error: 0.2909\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2375 - mean_absolute_error: 0.2375 - val_loss: 0.2918 - val_mean_absolute_error: 0.2918\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2370 - mean_absolute_error: 0.2370 - val_loss: 0.2929 - val_mean_absolute_error: 0.2929\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.2940 - val_mean_absolute_error: 0.2940\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2335 - mean_absolute_error: 0.2335 - val_loss: 0.2950 - val_mean_absolute_error: 0.2950\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2340 - mean_absolute_error: 0.2340 - val_loss: 0.2959 - val_mean_absolute_error: 0.2959\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2354 - mean_absolute_error: 0.2354 - val_loss: 0.2966 - val_mean_absolute_error: 0.2966\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2343 - mean_absolute_error: 0.2343 - val_loss: 0.2973 - val_mean_absolute_error: 0.2973\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2360 - mean_absolute_error: 0.2360 - val_loss: 0.2970 - val_mean_absolute_error: 0.2970\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2367 - mean_absolute_error: 0.2367 - val_loss: 0.2961 - val_mean_absolute_error: 0.2961\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2356 - mean_absolute_error: 0.2356 - val_loss: 0.2945 - val_mean_absolute_error: 0.2945\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2372 - mean_absolute_error: 0.2372 - val_loss: 0.2922 - val_mean_absolute_error: 0.2922\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2898 - val_mean_absolute_error: 0.2898\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2309 - mean_absolute_error: 0.2309 - val_loss: 0.2873 - val_mean_absolute_error: 0.2873\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2849 - val_mean_absolute_error: 0.2849\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2345 - mean_absolute_error: 0.2345 - val_loss: 0.2830 - val_mean_absolute_error: 0.2830\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2373 - mean_absolute_error: 0.2373 - val_loss: 0.2818 - val_mean_absolute_error: 0.2818\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2818 - val_mean_absolute_error: 0.2818\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2306 - mean_absolute_error: 0.2306 - val_loss: 0.2825 - val_mean_absolute_error: 0.2825\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2314 - mean_absolute_error: 0.2314 - val_loss: 0.2838 - val_mean_absolute_error: 0.2838\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2858 - val_mean_absolute_error: 0.2858\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2330 - mean_absolute_error: 0.2330 - val_loss: 0.2875 - val_mean_absolute_error: 0.2875\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2327 - mean_absolute_error: 0.2327 - val_loss: 0.2886 - val_mean_absolute_error: 0.2886\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2895 - val_mean_absolute_error: 0.2895\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2314 - mean_absolute_error: 0.2314 - val_loss: 0.2897 - val_mean_absolute_error: 0.2897\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2325 - mean_absolute_error: 0.2325 - val_loss: 0.2893 - val_mean_absolute_error: 0.2893\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2362 - mean_absolute_error: 0.2362 - val_loss: 0.2884 - val_mean_absolute_error: 0.2884\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2321 - mean_absolute_error: 0.2321 - val_loss: 0.2875 - val_mean_absolute_error: 0.2875\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2275 - mean_absolute_error: 0.2275 - val_loss: 0.2870 - val_mean_absolute_error: 0.2870\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2864 - val_mean_absolute_error: 0.2864\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2359 - mean_absolute_error: 0.2359 - val_loss: 0.2860 - val_mean_absolute_error: 0.2860\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2332 - mean_absolute_error: 0.2332 - val_loss: 0.2864 - val_mean_absolute_error: 0.2864\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2330 - mean_absolute_error: 0.2330 - val_loss: 0.2868 - val_mean_absolute_error: 0.2868\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2309 - mean_absolute_error: 0.2309 - val_loss: 0.2876 - val_mean_absolute_error: 0.2876\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2340 - mean_absolute_error: 0.2340 - val_loss: 0.2886 - val_mean_absolute_error: 0.2886\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2326 - mean_absolute_error: 0.2326 - val_loss: 0.2903 - val_mean_absolute_error: 0.2903\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2367 - mean_absolute_error: 0.2367 - val_loss: 0.2912 - val_mean_absolute_error: 0.2912\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2915 - val_mean_absolute_error: 0.2915\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2359 - mean_absolute_error: 0.2359 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2892 - val_mean_absolute_error: 0.2892\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2368 - mean_absolute_error: 0.2368 - val_loss: 0.2866 - val_mean_absolute_error: 0.2866\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2286 - mean_absolute_error: 0.2286 - val_loss: 0.2837 - val_mean_absolute_error: 0.2837\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2352 - mean_absolute_error: 0.2352 - val_loss: 0.2810 - val_mean_absolute_error: 0.2810\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2345 - mean_absolute_error: 0.2345 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2320 - mean_absolute_error: 0.2320 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2315 - mean_absolute_error: 0.2315 - val_loss: 0.2767 - val_mean_absolute_error: 0.2767\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2305 - mean_absolute_error: 0.2305 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2272 - mean_absolute_error: 0.2272 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2763 - val_mean_absolute_error: 0.2763\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2322 - mean_absolute_error: 0.2322 - val_loss: 0.2770 - val_mean_absolute_error: 0.2770\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2320 - mean_absolute_error: 0.2320 - val_loss: 0.2767 - val_mean_absolute_error: 0.2767\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2416 - mean_absolute_error: 0.2416 - val_loss: 0.2759 - val_mean_absolute_error: 0.2759\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2361 - mean_absolute_error: 0.2361 - val_loss: 0.2746 - val_mean_absolute_error: 0.2746\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2331 - mean_absolute_error: 0.2331 - val_loss: 0.2735 - val_mean_absolute_error: 0.2735\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2308 - mean_absolute_error: 0.2308 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2731 - val_mean_absolute_error: 0.2731\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2293 - mean_absolute_error: 0.2293 - val_loss: 0.2726 - val_mean_absolute_error: 0.2726\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2316 - mean_absolute_error: 0.2316 - val_loss: 0.2721 - val_mean_absolute_error: 0.2721\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2360 - mean_absolute_error: 0.2360 - val_loss: 0.2724 - val_mean_absolute_error: 0.2724\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2286 - mean_absolute_error: 0.2286 - val_loss: 0.2727 - val_mean_absolute_error: 0.2727\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2321 - mean_absolute_error: 0.2321 - val_loss: 0.2746 - val_mean_absolute_error: 0.2746\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2311 - mean_absolute_error: 0.2311 - val_loss: 0.2759 - val_mean_absolute_error: 0.2759\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2316 - mean_absolute_error: 0.2316 - val_loss: 0.2770 - val_mean_absolute_error: 0.2770\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2333 - mean_absolute_error: 0.2333 - val_loss: 0.2782 - val_mean_absolute_error: 0.2782\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2317 - mean_absolute_error: 0.2317 - val_loss: 0.2792 - val_mean_absolute_error: 0.2792\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2797 - val_mean_absolute_error: 0.2797\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2347 - mean_absolute_error: 0.2347 - val_loss: 0.2806 - val_mean_absolute_error: 0.2806\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2808 - val_mean_absolute_error: 0.2808\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2808 - val_mean_absolute_error: 0.2808\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2344 - mean_absolute_error: 0.2344 - val_loss: 0.2806 - val_mean_absolute_error: 0.2806\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2806 - val_mean_absolute_error: 0.2806\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2302 - mean_absolute_error: 0.2302 - val_loss: 0.2804 - val_mean_absolute_error: 0.2804\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2807 - val_mean_absolute_error: 0.2807\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2808 - val_mean_absolute_error: 0.2808\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2338 - mean_absolute_error: 0.2338 - val_loss: 0.2814 - val_mean_absolute_error: 0.2814\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2303 - mean_absolute_error: 0.2303 - val_loss: 0.2822 - val_mean_absolute_error: 0.2822\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2313 - mean_absolute_error: 0.2313 - val_loss: 0.2828 - val_mean_absolute_error: 0.2828\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2297 - mean_absolute_error: 0.2297 - val_loss: 0.2828 - val_mean_absolute_error: 0.2828\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2820 - val_mean_absolute_error: 0.2820\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2811 - val_mean_absolute_error: 0.2811\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2799 - val_mean_absolute_error: 0.2799\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2787 - val_mean_absolute_error: 0.2787\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2368 - mean_absolute_error: 0.2368 - val_loss: 0.2785 - val_mean_absolute_error: 0.2785\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2365 - mean_absolute_error: 0.2365 - val_loss: 0.2786 - val_mean_absolute_error: 0.2786\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2314 - mean_absolute_error: 0.2314 - val_loss: 0.2784 - val_mean_absolute_error: 0.2784\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2293 - mean_absolute_error: 0.2293 - val_loss: 0.2781 - val_mean_absolute_error: 0.2781\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2318 - mean_absolute_error: 0.2318 - val_loss: 0.2783 - val_mean_absolute_error: 0.2783\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2321 - mean_absolute_error: 0.2321 - val_loss: 0.2797 - val_mean_absolute_error: 0.2797\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2307 - mean_absolute_error: 0.2307 - val_loss: 0.2803 - val_mean_absolute_error: 0.2803\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2330 - mean_absolute_error: 0.2330 - val_loss: 0.2805 - val_mean_absolute_error: 0.2805\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2270 - mean_absolute_error: 0.2270 - val_loss: 0.2805 - val_mean_absolute_error: 0.2805\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2313 - mean_absolute_error: 0.2313 - val_loss: 0.2803 - val_mean_absolute_error: 0.2803\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2321 - mean_absolute_error: 0.2321 - val_loss: 0.2800 - val_mean_absolute_error: 0.2800\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2341 - mean_absolute_error: 0.2341 - val_loss: 0.2792 - val_mean_absolute_error: 0.2792\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2329 - mean_absolute_error: 0.2329 - val_loss: 0.2754 - val_mean_absolute_error: 0.2754\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2346 - mean_absolute_error: 0.2346 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2292 - mean_absolute_error: 0.2292 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2309 - mean_absolute_error: 0.2309 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2757 - val_mean_absolute_error: 0.2757\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2306 - mean_absolute_error: 0.2306 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2346 - mean_absolute_error: 0.2346 - val_loss: 0.2779 - val_mean_absolute_error: 0.2779\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2787 - val_mean_absolute_error: 0.2787\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2791 - val_mean_absolute_error: 0.2791\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2789 - val_mean_absolute_error: 0.2789\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2264 - mean_absolute_error: 0.2264 - val_loss: 0.2783 - val_mean_absolute_error: 0.2783\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2275 - mean_absolute_error: 0.2275 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2369 - mean_absolute_error: 0.2369 - val_loss: 0.2779 - val_mean_absolute_error: 0.2779\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2307 - mean_absolute_error: 0.2307 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2333 - mean_absolute_error: 0.2333 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2305 - mean_absolute_error: 0.2305 - val_loss: 0.2767 - val_mean_absolute_error: 0.2767\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2762 - val_mean_absolute_error: 0.2762\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2281 - mean_absolute_error: 0.2281 - val_loss: 0.2759 - val_mean_absolute_error: 0.2759\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2311 - mean_absolute_error: 0.2311 - val_loss: 0.2759 - val_mean_absolute_error: 0.2759\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2297 - mean_absolute_error: 0.2297 - val_loss: 0.2763 - val_mean_absolute_error: 0.2763\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2325 - mean_absolute_error: 0.2325 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2291 - mean_absolute_error: 0.2291 - val_loss: 0.2775 - val_mean_absolute_error: 0.2775\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2283 - mean_absolute_error: 0.2283 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2292 - mean_absolute_error: 0.2292 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2779 - val_mean_absolute_error: 0.2779\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2281 - mean_absolute_error: 0.2281 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2253 - mean_absolute_error: 0.2253 - val_loss: 0.2773 - val_mean_absolute_error: 0.2773\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2282 - mean_absolute_error: 0.2282 - val_loss: 0.2768 - val_mean_absolute_error: 0.2768\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2337 - mean_absolute_error: 0.2337 - val_loss: 0.2761 - val_mean_absolute_error: 0.2761\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2752 - val_mean_absolute_error: 0.2752\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2740 - val_mean_absolute_error: 0.2740\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2315 - mean_absolute_error: 0.2315 - val_loss: 0.2731 - val_mean_absolute_error: 0.2731\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2291 - mean_absolute_error: 0.2291 - val_loss: 0.2729 - val_mean_absolute_error: 0.2729\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2304 - mean_absolute_error: 0.2304 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2282 - mean_absolute_error: 0.2282 - val_loss: 0.2739 - val_mean_absolute_error: 0.2739\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2286 - mean_absolute_error: 0.2286 - val_loss: 0.2744 - val_mean_absolute_error: 0.2744\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2751 - val_mean_absolute_error: 0.2751\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2755 - val_mean_absolute_error: 0.2755\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2327 - mean_absolute_error: 0.2327 - val_loss: 0.2761 - val_mean_absolute_error: 0.2761\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2765 - val_mean_absolute_error: 0.2765\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2302 - mean_absolute_error: 0.2302 - val_loss: 0.2763 - val_mean_absolute_error: 0.2763\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2760 - val_mean_absolute_error: 0.2760\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2755 - val_mean_absolute_error: 0.2755\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2309 - mean_absolute_error: 0.2309 - val_loss: 0.2751 - val_mean_absolute_error: 0.2751\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2363 - mean_absolute_error: 0.2363 - val_loss: 0.2751 - val_mean_absolute_error: 0.2751\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2263 - mean_absolute_error: 0.2263 - val_loss: 0.2752 - val_mean_absolute_error: 0.2752\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2302 - mean_absolute_error: 0.2302 - val_loss: 0.2753 - val_mean_absolute_error: 0.2753\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2336 - mean_absolute_error: 0.2336 - val_loss: 0.2754 - val_mean_absolute_error: 0.2754\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2756 - val_mean_absolute_error: 0.2756\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2339 - mean_absolute_error: 0.2339 - val_loss: 0.2758 - val_mean_absolute_error: 0.2758\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2763 - val_mean_absolute_error: 0.2763\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2311 - mean_absolute_error: 0.2311 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2317 - mean_absolute_error: 0.2317 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2268 - mean_absolute_error: 0.2268 - val_loss: 0.2780 - val_mean_absolute_error: 0.2780\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2292 - mean_absolute_error: 0.2292 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2308 - mean_absolute_error: 0.2308 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2320 - mean_absolute_error: 0.2320 - val_loss: 0.2775 - val_mean_absolute_error: 0.2775\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2284 - mean_absolute_error: 0.2284 - val_loss: 0.2782 - val_mean_absolute_error: 0.2782\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2305 - mean_absolute_error: 0.2305 - val_loss: 0.2785 - val_mean_absolute_error: 0.2785\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2309 - mean_absolute_error: 0.2309 - val_loss: 0.2792 - val_mean_absolute_error: 0.2792\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2284 - mean_absolute_error: 0.2284 - val_loss: 0.2800 - val_mean_absolute_error: 0.2800\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2344 - mean_absolute_error: 0.2344 - val_loss: 0.2805 - val_mean_absolute_error: 0.2805\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2314 - mean_absolute_error: 0.2314 - val_loss: 0.2809 - val_mean_absolute_error: 0.2809\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2284 - mean_absolute_error: 0.2284 - val_loss: 0.2808 - val_mean_absolute_error: 0.2808\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2265 - mean_absolute_error: 0.2265 - val_loss: 0.2806 - val_mean_absolute_error: 0.2806\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2278 - mean_absolute_error: 0.2278 - val_loss: 0.2797 - val_mean_absolute_error: 0.2797\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2302 - mean_absolute_error: 0.2302 - val_loss: 0.2786 - val_mean_absolute_error: 0.2786\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2303 - mean_absolute_error: 0.2303 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2774 - val_mean_absolute_error: 0.2774\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2304 - mean_absolute_error: 0.2304 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2270 - mean_absolute_error: 0.2270 - val_loss: 0.2783 - val_mean_absolute_error: 0.2783\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2779 - val_mean_absolute_error: 0.2779\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2770 - val_mean_absolute_error: 0.2770\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2350 - mean_absolute_error: 0.2350 - val_loss: 0.2755 - val_mean_absolute_error: 0.2755\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2742 - val_mean_absolute_error: 0.2742\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2728 - val_mean_absolute_error: 0.2728\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2728 - val_mean_absolute_error: 0.2728\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2275 - mean_absolute_error: 0.2275 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2304 - mean_absolute_error: 0.2304 - val_loss: 0.2737 - val_mean_absolute_error: 0.2737\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2278 - mean_absolute_error: 0.2278 - val_loss: 0.2740 - val_mean_absolute_error: 0.2740\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2271 - mean_absolute_error: 0.2271 - val_loss: 0.2742 - val_mean_absolute_error: 0.2742\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2741 - val_mean_absolute_error: 0.2741\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2272 - mean_absolute_error: 0.2272 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2291 - mean_absolute_error: 0.2291 - val_loss: 0.2727 - val_mean_absolute_error: 0.2727\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2285 - mean_absolute_error: 0.2285 - val_loss: 0.2725 - val_mean_absolute_error: 0.2725\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2717 - val_mean_absolute_error: 0.2717\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2316 - mean_absolute_error: 0.2316 - val_loss: 0.2704 - val_mean_absolute_error: 0.2704\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2305 - mean_absolute_error: 0.2305 - val_loss: 0.2696 - val_mean_absolute_error: 0.2696\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2292 - mean_absolute_error: 0.2292 - val_loss: 0.2697 - val_mean_absolute_error: 0.2697\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2318 - mean_absolute_error: 0.2318 - val_loss: 0.2700 - val_mean_absolute_error: 0.2700\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2266 - mean_absolute_error: 0.2266 - val_loss: 0.2704 - val_mean_absolute_error: 0.2704\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2702 - val_mean_absolute_error: 0.2702\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2259 - mean_absolute_error: 0.2259 - val_loss: 0.2691 - val_mean_absolute_error: 0.2691\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2268 - mean_absolute_error: 0.2268 - val_loss: 0.2683 - val_mean_absolute_error: 0.2683\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2319 - mean_absolute_error: 0.2319 - val_loss: 0.2681 - val_mean_absolute_error: 0.2681\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2311 - mean_absolute_error: 0.2311 - val_loss: 0.2684 - val_mean_absolute_error: 0.2684\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2308 - mean_absolute_error: 0.2308 - val_loss: 0.2686 - val_mean_absolute_error: 0.2686\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2699 - val_mean_absolute_error: 0.2699\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2272 - mean_absolute_error: 0.2272 - val_loss: 0.2708 - val_mean_absolute_error: 0.2708\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2268 - mean_absolute_error: 0.2268 - val_loss: 0.2720 - val_mean_absolute_error: 0.2720\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2736 - val_mean_absolute_error: 0.2736\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2748 - val_mean_absolute_error: 0.2748\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2752 - val_mean_absolute_error: 0.2752\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2337 - mean_absolute_error: 0.2337 - val_loss: 0.2754 - val_mean_absolute_error: 0.2754\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2356 - mean_absolute_error: 0.2356 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2285 - mean_absolute_error: 0.2285 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2305 - mean_absolute_error: 0.2305 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2748 - val_mean_absolute_error: 0.2748\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2292 - mean_absolute_error: 0.2292 - val_loss: 0.2746 - val_mean_absolute_error: 0.2746\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2271 - mean_absolute_error: 0.2271 - val_loss: 0.2746 - val_mean_absolute_error: 0.2746\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2349 - mean_absolute_error: 0.2349 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2283 - mean_absolute_error: 0.2283 - val_loss: 0.2757 - val_mean_absolute_error: 0.2757\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2290 - mean_absolute_error: 0.2290 - val_loss: 0.2765 - val_mean_absolute_error: 0.2765\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2252 - mean_absolute_error: 0.2252 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2775 - val_mean_absolute_error: 0.2775\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2253 - mean_absolute_error: 0.2253 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2264 - mean_absolute_error: 0.2264 - val_loss: 0.2773 - val_mean_absolute_error: 0.2773\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2770 - val_mean_absolute_error: 0.2770\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2335 - mean_absolute_error: 0.2335 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2777 - val_mean_absolute_error: 0.2777\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2317 - mean_absolute_error: 0.2317 - val_loss: 0.2774 - val_mean_absolute_error: 0.2774\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2770 - val_mean_absolute_error: 0.2770\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2248 - mean_absolute_error: 0.2248 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2269 - mean_absolute_error: 0.2269 - val_loss: 0.2751 - val_mean_absolute_error: 0.2751\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2303 - mean_absolute_error: 0.2303 - val_loss: 0.2737 - val_mean_absolute_error: 0.2737\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2319 - mean_absolute_error: 0.2319 - val_loss: 0.2725 - val_mean_absolute_error: 0.2725\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.2723 - val_mean_absolute_error: 0.2723\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2346 - mean_absolute_error: 0.2346 - val_loss: 0.2723 - val_mean_absolute_error: 0.2723\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2319 - mean_absolute_error: 0.2319 - val_loss: 0.2727 - val_mean_absolute_error: 0.2727\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2265 - mean_absolute_error: 0.2265 - val_loss: 0.2736 - val_mean_absolute_error: 0.2736\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2293 - mean_absolute_error: 0.2293 - val_loss: 0.2743 - val_mean_absolute_error: 0.2743\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2271 - mean_absolute_error: 0.2271 - val_loss: 0.2755 - val_mean_absolute_error: 0.2755\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2259 - mean_absolute_error: 0.2259 - val_loss: 0.2765 - val_mean_absolute_error: 0.2765\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2291 - mean_absolute_error: 0.2291 - val_loss: 0.2771 - val_mean_absolute_error: 0.2771\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2760 - val_mean_absolute_error: 0.2760\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2747 - val_mean_absolute_error: 0.2747\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2261 - mean_absolute_error: 0.2261 - val_loss: 0.2736 - val_mean_absolute_error: 0.2736\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2343 - mean_absolute_error: 0.2343 - val_loss: 0.2721 - val_mean_absolute_error: 0.2721\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2258 - mean_absolute_error: 0.2258 - val_loss: 0.2706 - val_mean_absolute_error: 0.2706\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2275 - mean_absolute_error: 0.2275 - val_loss: 0.2703 - val_mean_absolute_error: 0.2703\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2293 - mean_absolute_error: 0.2293 - val_loss: 0.2702 - val_mean_absolute_error: 0.2702\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2705 - val_mean_absolute_error: 0.2705\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2258 - mean_absolute_error: 0.2258 - val_loss: 0.2722 - val_mean_absolute_error: 0.2722\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2281 - mean_absolute_error: 0.2281 - val_loss: 0.2739 - val_mean_absolute_error: 0.2739\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2281 - mean_absolute_error: 0.2281 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2252 - mean_absolute_error: 0.2252 - val_loss: 0.2756 - val_mean_absolute_error: 0.2756\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2262 - mean_absolute_error: 0.2262 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2277 - mean_absolute_error: 0.2277 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2781 - val_mean_absolute_error: 0.2781\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2295 - mean_absolute_error: 0.2295 - val_loss: 0.2787 - val_mean_absolute_error: 0.2787\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2786 - val_mean_absolute_error: 0.2786\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2240 - mean_absolute_error: 0.2240 - val_loss: 0.2794 - val_mean_absolute_error: 0.2794\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2799 - val_mean_absolute_error: 0.2799\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2236 - mean_absolute_error: 0.2236 - val_loss: 0.2805 - val_mean_absolute_error: 0.2805\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2270 - mean_absolute_error: 0.2270 - val_loss: 0.2814 - val_mean_absolute_error: 0.2814\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2826 - val_mean_absolute_error: 0.2826\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2270 - mean_absolute_error: 0.2270 - val_loss: 0.2836 - val_mean_absolute_error: 0.2836\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2314 - mean_absolute_error: 0.2314 - val_loss: 0.2841 - val_mean_absolute_error: 0.2841\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2312 - mean_absolute_error: 0.2312 - val_loss: 0.2847 - val_mean_absolute_error: 0.2847\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2275 - mean_absolute_error: 0.2275 - val_loss: 0.2853 - val_mean_absolute_error: 0.2853\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2281 - mean_absolute_error: 0.2281 - val_loss: 0.2863 - val_mean_absolute_error: 0.2863\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2274 - mean_absolute_error: 0.2274 - val_loss: 0.2865 - val_mean_absolute_error: 0.2865\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2859 - val_mean_absolute_error: 0.2859\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2232 - mean_absolute_error: 0.2232 - val_loss: 0.2853 - val_mean_absolute_error: 0.2853\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2267 - mean_absolute_error: 0.2267 - val_loss: 0.2847 - val_mean_absolute_error: 0.2847\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2374 - mean_absolute_error: 0.2374 - val_loss: 0.2845 - val_mean_absolute_error: 0.2845\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2841 - val_mean_absolute_error: 0.2841\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2321 - mean_absolute_error: 0.2321 - val_loss: 0.2838 - val_mean_absolute_error: 0.2838\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2271 - mean_absolute_error: 0.2271 - val_loss: 0.2838 - val_mean_absolute_error: 0.2838\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2301 - mean_absolute_error: 0.2301 - val_loss: 0.2834 - val_mean_absolute_error: 0.2834\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2294 - mean_absolute_error: 0.2294 - val_loss: 0.2833 - val_mean_absolute_error: 0.2833\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2277 - mean_absolute_error: 0.2277 - val_loss: 0.2836 - val_mean_absolute_error: 0.2836\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2294 - mean_absolute_error: 0.2294 - val_loss: 0.2835 - val_mean_absolute_error: 0.2835\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2293 - mean_absolute_error: 0.2293 - val_loss: 0.2831 - val_mean_absolute_error: 0.2831\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2273 - mean_absolute_error: 0.2273 - val_loss: 0.2833 - val_mean_absolute_error: 0.2833\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "# loss function\n",
    "msle = MeanSquaredLogarithmicError()\n",
    "model.compile(\n",
    "    loss='mean_absolute_error', \n",
    "    optimizer=Adam(learning_rate=0.002), \n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    X_train_shaped, \n",
    "    y_train.values, \n",
    "    epochs=500, \n",
    "    batch_size=7,\n",
    "    validation_data=(X_test_shaped, y_test.values)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a3d1d78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "YGIvxTu_Hh5_",
    "outputId": "9673551b-8868-44f4-af4f-f5114090ba52",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history, key):\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history['val_'+key])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(key)\n",
    "    plt.legend([key, 'val_'+key])\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the history\n",
    "plot_history(history, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1d6699e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0V8NZBqnMo-X",
    "outputId": "58569319-fa3b-42c1-f83b-3e1f5e9552bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.27337\n",
      "MSE: 0.699\n",
      "RMSE: 0.836\n",
      "MAE: 0.224\n",
      "\n",
      "Test:\n",
      "R-squared: -1.87515\n",
      "MSE: 0.14\n",
      "RMSE: 0.375\n",
      "MAE: 0.283\n"
     ]
    }
   ],
   "source": [
    "print('Train:')\n",
    "r=print_evaluate(y_train, model.predict(X_train_shaped))\n",
    "print('\\nTest:')\n",
    "s=print_evaluate(y_test, model.predict(X_test_shaped))\n",
    "\n",
    "save_results('Neural network (target = inflation) ', r, s, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104062df",
   "metadata": {},
   "source": [
    "### 4.2 target = dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d29114d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "iwJm7LUxHiFX",
    "outputId": "b992eff0-0b87-489e-f65c-b0e312367493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8614 - mean_absolute_error: 0.8614 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8571 - val_mean_absolute_error: 0.8571\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8570 - val_mean_absolute_error: 0.8570\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8615 - mean_absolute_error: 0.8615 - val_loss: 0.8570 - val_mean_absolute_error: 0.8570\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8614 - mean_absolute_error: 0.8614 - val_loss: 0.8570 - val_mean_absolute_error: 0.8570\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8611 - mean_absolute_error: 0.8611 - val_loss: 0.8570 - val_mean_absolute_error: 0.8570\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8614 - mean_absolute_error: 0.8614 - val_loss: 0.8570 - val_mean_absolute_error: 0.8570\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8614 - mean_absolute_error: 0.8614 - val_loss: 0.8569 - val_mean_absolute_error: 0.8569\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8607 - mean_absolute_error: 0.8607 - val_loss: 0.8569 - val_mean_absolute_error: 0.8569\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8608 - mean_absolute_error: 0.8608 - val_loss: 0.8568 - val_mean_absolute_error: 0.8568\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8614 - mean_absolute_error: 0.8614 - val_loss: 0.8567 - val_mean_absolute_error: 0.8567\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8613 - mean_absolute_error: 0.8613 - val_loss: 0.8566 - val_mean_absolute_error: 0.8566\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8610 - mean_absolute_error: 0.8610 - val_loss: 0.8565 - val_mean_absolute_error: 0.8565\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8612 - mean_absolute_error: 0.8612 - val_loss: 0.8563 - val_mean_absolute_error: 0.8563\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8605 - mean_absolute_error: 0.8605 - val_loss: 0.8561 - val_mean_absolute_error: 0.8561\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8603 - mean_absolute_error: 0.8603 - val_loss: 0.8559 - val_mean_absolute_error: 0.8559\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8607 - mean_absolute_error: 0.8607 - val_loss: 0.8555 - val_mean_absolute_error: 0.8555\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8596 - mean_absolute_error: 0.8596 - val_loss: 0.8551 - val_mean_absolute_error: 0.8551\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8602 - mean_absolute_error: 0.8602 - val_loss: 0.8545 - val_mean_absolute_error: 0.8545\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8587 - mean_absolute_error: 0.8587 - val_loss: 0.8539 - val_mean_absolute_error: 0.8539\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8590 - mean_absolute_error: 0.8590 - val_loss: 0.8530 - val_mean_absolute_error: 0.8530\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8591 - mean_absolute_error: 0.8591 - val_loss: 0.8520 - val_mean_absolute_error: 0.8520\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8558 - mean_absolute_error: 0.8558 - val_loss: 0.8507 - val_mean_absolute_error: 0.8507\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8567 - mean_absolute_error: 0.8567 - val_loss: 0.8492 - val_mean_absolute_error: 0.8492\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8566 - mean_absolute_error: 0.8566 - val_loss: 0.8474 - val_mean_absolute_error: 0.8474\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8491 - mean_absolute_error: 0.8491 - val_loss: 0.8453 - val_mean_absolute_error: 0.8453\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8470 - mean_absolute_error: 0.8470 - val_loss: 0.8429 - val_mean_absolute_error: 0.8429\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8463 - mean_absolute_error: 0.8463 - val_loss: 0.8406 - val_mean_absolute_error: 0.8406\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8414 - mean_absolute_error: 0.8414 - val_loss: 0.8381 - val_mean_absolute_error: 0.8381\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8369 - mean_absolute_error: 0.8369 - val_loss: 0.8356 - val_mean_absolute_error: 0.8356\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8395 - mean_absolute_error: 0.8395 - val_loss: 0.8327 - val_mean_absolute_error: 0.8327\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8253 - mean_absolute_error: 0.8253 - val_loss: 0.8301 - val_mean_absolute_error: 0.8301\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8148 - mean_absolute_error: 0.8148 - val_loss: 0.8273 - val_mean_absolute_error: 0.8273\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8090 - mean_absolute_error: 0.8090 - val_loss: 0.8241 - val_mean_absolute_error: 0.8241\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8001 - mean_absolute_error: 0.8001 - val_loss: 0.8199 - val_mean_absolute_error: 0.8199\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8009 - mean_absolute_error: 0.8009 - val_loss: 0.8142 - val_mean_absolute_error: 0.8142\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7789 - mean_absolute_error: 0.7789 - val_loss: 0.8063 - val_mean_absolute_error: 0.8063\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7587 - mean_absolute_error: 0.7587 - val_loss: 0.7956 - val_mean_absolute_error: 0.7956\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7588 - mean_absolute_error: 0.7588 - val_loss: 0.7810 - val_mean_absolute_error: 0.7810\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7176 - mean_absolute_error: 0.7176 - val_loss: 0.7610 - val_mean_absolute_error: 0.7610\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6933 - mean_absolute_error: 0.6933 - val_loss: 0.7341 - val_mean_absolute_error: 0.7341\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6486 - mean_absolute_error: 0.6486 - val_loss: 0.6995 - val_mean_absolute_error: 0.6995\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6251 - mean_absolute_error: 0.6251 - val_loss: 0.6573 - val_mean_absolute_error: 0.6573\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5985 - mean_absolute_error: 0.5985 - val_loss: 0.6103 - val_mean_absolute_error: 0.6103\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5566 - mean_absolute_error: 0.5566 - val_loss: 0.5612 - val_mean_absolute_error: 0.5612\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5187 - mean_absolute_error: 0.5187 - val_loss: 0.5110 - val_mean_absolute_error: 0.5110\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4774 - mean_absolute_error: 0.4774 - val_loss: 0.4627 - val_mean_absolute_error: 0.4627\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4416 - mean_absolute_error: 0.4416 - val_loss: 0.4190 - val_mean_absolute_error: 0.4190\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4092 - mean_absolute_error: 0.4092 - val_loss: 0.3804 - val_mean_absolute_error: 0.3804\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3774 - mean_absolute_error: 0.3774 - val_loss: 0.3452 - val_mean_absolute_error: 0.3452\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3528 - mean_absolute_error: 0.3528 - val_loss: 0.3139 - val_mean_absolute_error: 0.3139\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3360 - mean_absolute_error: 0.3360 - val_loss: 0.2833 - val_mean_absolute_error: 0.2833\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3008 - mean_absolute_error: 0.3008 - val_loss: 0.2563 - val_mean_absolute_error: 0.2563\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2856 - mean_absolute_error: 0.2856 - val_loss: 0.2331 - val_mean_absolute_error: 0.2331\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2713 - mean_absolute_error: 0.2713 - val_loss: 0.2105 - val_mean_absolute_error: 0.2105\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2727 - mean_absolute_error: 0.2727 - val_loss: 0.1877 - val_mean_absolute_error: 0.1877\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2326 - mean_absolute_error: 0.2326 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2247 - mean_absolute_error: 0.2247 - val_loss: 0.1315 - val_mean_absolute_error: 0.1315\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1965 - mean_absolute_error: 0.1965 - val_loss: 0.1027 - val_mean_absolute_error: 0.1027\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1719 - mean_absolute_error: 0.1719 - val_loss: 0.0758 - val_mean_absolute_error: 0.0758\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1447 - mean_absolute_error: 0.1447 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1355 - mean_absolute_error: 0.1355 - val_loss: 0.0455 - val_mean_absolute_error: 0.0455\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1206 - mean_absolute_error: 0.1206 - val_loss: 0.0406 - val_mean_absolute_error: 0.0406\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.0375 - val_mean_absolute_error: 0.0375\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0333 - val_mean_absolute_error: 0.0333\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0662 - mean_absolute_error: 0.0662 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0584 - mean_absolute_error: 0.0584 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0551 - mean_absolute_error: 0.0551 - val_loss: 0.0272 - val_mean_absolute_error: 0.0272\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0473 - mean_absolute_error: 0.0473 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0483 - mean_absolute_error: 0.0483 - val_loss: 0.0309 - val_mean_absolute_error: 0.0309\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0517 - mean_absolute_error: 0.0517 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0474 - mean_absolute_error: 0.0474 - val_loss: 0.0278 - val_mean_absolute_error: 0.0278\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0462 - mean_absolute_error: 0.0462 - val_loss: 0.0243 - val_mean_absolute_error: 0.0243\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0420 - mean_absolute_error: 0.0420 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0367 - mean_absolute_error: 0.0367 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0287 - mean_absolute_error: 0.0287 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0217 - mean_absolute_error: 0.0217 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0110 - val_mean_absolute_error: 0.0110\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0110 - val_mean_absolute_error: 0.0110\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0229 - mean_absolute_error: 0.0229 - val_loss: 0.0138 - val_mean_absolute_error: 0.0138\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0220 - mean_absolute_error: 0.0220 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0234 - mean_absolute_error: 0.0234 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0252 - mean_absolute_error: 0.0252 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0257 - mean_absolute_error: 0.0257 - val_loss: 0.0131 - val_mean_absolute_error: 0.0131\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0238 - mean_absolute_error: 0.0238 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0235 - mean_absolute_error: 0.0235 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0103 - val_mean_absolute_error: 0.0103\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0095 - val_mean_absolute_error: 0.0095\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0092 - val_mean_absolute_error: 0.0092\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0092 - val_mean_absolute_error: 0.0092\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0090 - val_mean_absolute_error: 0.0090\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0086 - val_mean_absolute_error: 0.0086\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0131 - mean_absolute_error: 0.0131 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0083 - val_mean_absolute_error: 0.0083\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0083 - val_mean_absolute_error: 0.0083\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0082 - val_mean_absolute_error: 0.0082\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0082 - val_mean_absolute_error: 0.0082\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0083 - val_mean_absolute_error: 0.0083\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_absolute_error: 0.0033 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0082 - val_mean_absolute_error: 0.0082\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0082 - val_mean_absolute_error: 0.0082\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_absolute_error: 0.0031 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_absolute_error: 0.0032 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_absolute_error: 0.0032 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mean_absolute_error: 0.0032 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_absolute_error: 0.0027 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_absolute_error: 0.0032 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - mean_absolute_error: 0.0027 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - mean_absolute_error: 0.0032 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_absolute_error: 0.0031 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_absolute_error: 0.0033 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "# loss function\n",
    "model.compile(\n",
    "    loss='mean_absolute_error', \n",
    "    optimizer=Adam(learning_rate=0.002), \n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    X_train_shaped, \n",
    "    y_train2.values, \n",
    "    epochs=500, \n",
    "    batch_size=7,\n",
    "    validation_data=(X_test_shaped, y_test2.values)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04960592",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "O7enFQKNM3Wy",
    "outputId": "431854ee-526c-4f3d-db4c-14ee278bfaae",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history\n",
    "plot_history(history, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f79a0afa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zodDvzEJMkDO",
    "outputId": "29c3eb3f-e5e6-4032-bfa3-53a074a5b160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "R-squared: 0.89829\n",
      "MSE: 0.0\n",
      "RMSE: 0.008\n",
      "MAE: 0.005\n",
      "\n",
      "Test:\n",
      "R-squared: 0.68667\n",
      "MSE: 0.0\n",
      "RMSE: 0.008\n",
      "MAE: 0.008\n"
     ]
    }
   ],
   "source": [
    "print('Train:')\n",
    "r=print_evaluate(y_train2, model.predict(X_train_shaped))\n",
    "print('\\nTest:')\n",
    "s=print_evaluate(y_test2, model.predict(X_test_shaped))\n",
    "\n",
    "save_results('Neural network (target = dollar exchange rate)', r, s, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "80ff3793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_Train</th>\n",
       "      <th>r2_Test</th>\n",
       "      <th>MSE_Train</th>\n",
       "      <th>MSE_Test</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>MAE_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural network (target = inflation)</th>\n",
       "      <td>0.273372</td>\n",
       "      <td>-1.875154</td>\n",
       "      <td>0.699424</td>\n",
       "      <td>0.140384</td>\n",
       "      <td>0.836316</td>\n",
       "      <td>0.374678</td>\n",
       "      <td>0.224131</td>\n",
       "      <td>0.283316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural network (target = dollar exchange rate)</th>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.686669</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.007577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                r2_Train   r2_Test  MSE_Train  \\\n",
       "Neural network (target = inflation)             0.273372 -1.875154   0.699424   \n",
       "Neural network (target = dollar exchange rate)  0.898291  0.686669   0.000057   \n",
       "\n",
       "                                                MSE_Test  RMSE_Train  \\\n",
       "Neural network (target = inflation)             0.140384    0.836316   \n",
       "Neural network (target = dollar exchange rate)  0.000071    0.007546   \n",
       "\n",
       "                                                RMSE_Test  MAE_Train  MAE_Test  \n",
       "Neural network (target = inflation)              0.374678   0.224131  0.283316  \n",
       "Neural network (target = dollar exchange rate)   0.008413   0.004671  0.007577  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_df(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf21faa",
   "metadata": {},
   "source": [
    "As a result, when targent is changes in inflation, neural network models failed to outperform  RFE with XGBoost regression. This might be due to the high dimensionality and sparse characteristics of the textual data.  But our Neural Network performs better than RFE with XGBoost regressior model when target is dollar exchange rate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
